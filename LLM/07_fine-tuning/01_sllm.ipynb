{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d71ff138-70b1-49d7-bfa0-197d28e41f2a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.49.0)\n",
      "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.66.3)\n",
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (1.5.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.29.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.24.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (4.0.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.9.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.10.6)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.6)\n",
      "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.1.0+cu118)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.4)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.1.3)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2022.12.7)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (2025.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->accelerate) (3.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->accelerate) (2.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.1.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.13)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.0.0->accelerate) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.0.0->accelerate) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers openai accelerate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ca0fa2-9ab7-4a1f-8c12-090c88489e23",
   "metadata": {},
   "source": [
    "### sLLM-LLM 응답 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f49c6bfd-bb2c-4ed6-bee3-ccfbfeb477e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Explain the theory of relativity in simple terms.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6d5cb4-c5e6-4148-a91a-c8c64da818a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_token = \"your_keys\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b1c9e9a-6dce-4a9d-80fb-3e765cd33dbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcdfd1862bac4698b2a0415a960cd429",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "sllm_model_name = \"meta-llama/Llama-2-7b-hf\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(sllm_model_name, token=hf_token)\n",
    "sllm = AutoModelForCausalLM.from_pretrained(sllm_model_name, token=hf_token, device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8778ccc7-9bb3-4383-93df-5f3bbfc4b5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(sllm.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70018b1c-e627-4d6e-ab77-5468b4a5e90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = sllm.generate(**inputs, max_length=500)\n",
    "sllm_res = tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6137e1bb-4ec2-4bd6-95b2-ca5216c0cac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "openai.api_key = \"your_keys\"\n",
    "\n",
    "gpt_res = openai.chat.completions.create(\n",
    "    model='gpt-4o-mini',\n",
    "    messages=[{\"role\":\"user\", \"content\":prompt}]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "331526e3-5d5f-4f9e-89db-daa3cff870e7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explain the theory of relativity in simple terms.\n",
      "The theory of relativity is a theory which explains the relationship between space, time, and matter. It is based on the fact that space and time are relative, not absolute.\n",
      "The theory of relativity was developed by Albert Einstein in 1905. He was trying to explain why the speed of light was constant, no matter how fast an object was moving.\n",
      "The theory of relativity states that time slows down for objects moving fast, and that space expands when an object is moving fast.\n",
      "The theory of relativity is a theory which explains the relationship between space, time, and matter. It is based on the fact that space and time are relative, not absolute. The theory of relativity was developed by Albert Einstein in 1905. He was trying to explain why the speed of light was constant, no matter how fast an object was moving. The theory of relativity states that time slows down for objects moving fast, and that space expands when an object is moving fast.\n",
      "The theory of relativity is a theory which explains the relationship between space, time, and matter. It is based on the fact that space and time are relative, not absolute. The theory of relativity was developed by Albert Einstein in 1905. He was trying to explain why the speed of light was constant, no matter how fast an object was moving. The theory of relativity states that time slows down for objects moving fast, and that space expands when an object is moving fast.\n",
      "The theory of relativity is a theory which explains the relationship between space, time, and matter. It is based on the fact that space and time are relative, not absolute. The theory of relativity was developed by Albert Einstein in 1905. He was trying to explain why the speed of light was constant, no matter how fast an object was moving. The theory of relativity states that time slows down for objects moving fast, and that space expands when an object is moving fast.\n",
      "The theory of relativity is a theory which explains the relationship between space, time, and matter. It is based on the fact that space and time are relative, not absolute. The theory of relativity was developed by Albert Einstein in 1905. He was trying to explain why the speed of light was\n"
     ]
    }
   ],
   "source": [
    "print(sllm_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "144fe50c-adb6-43b1-922f-7f3636f57faa",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The theory of relativity, developed by Albert Einstein in the early 20th century, is actually two theories: special relativity and general relativity. Here’s a simple breakdown of both:\n",
      "\n",
      "### Special Relativity\n",
      "1. **Speed of Light is Constant**: No matter how fast you're moving, the speed of light in a vacuum is always the same (about 299,792 kilometers per second).\n",
      "  \n",
      "2. **Time Dilation**: Time can pass at different rates depending on how fast you're moving. If you were traveling near the speed of light, time would slow down for you compared to someone who is stationary.\n",
      "\n",
      "3. **Length Contraction**: Objects moving at high speeds will appear shorter in the direction of motion, as observed from a stationary point of view.\n",
      "\n",
      "4. **E=mc²**: This famous equation means that energy (E) and mass (m) are interchangeable; they are different forms of the same thing. A small amount of mass can be converted into a large amount of energy.\n",
      "\n",
      "### General Relativity\n",
      "1. **Gravity as Curvature**: Instead of thinking of gravity as a force, general relativity describes it as the bending of space and time (spacetime) caused by mass. Massive objects like the Earth curve the space around them, and this curvature affects how objects move.\n",
      "\n",
      "2. **Effects on Time**: Similar to special relativity, general relativity shows that time runs slower in stronger gravitational fields. For example, a clock on a mountain (weaker gravity) ticks slightly faster than a clock at sea level (stronger gravity).\n",
      "\n",
      "3. **Black Holes and Cosmology**: General relativity predicts the existence of black holes and helps us understand the behavior of the universe, including the expansion of space.\n",
      "\n",
      "In summary, the theory of relativity tells us that the laws of physics are the same for everyone, regardless of how they move, and that gravity is the result of warping space and time around massive objects. It has changed our understanding of time, space, and the universe as a whole.\n"
     ]
    }
   ],
   "source": [
    "print(gpt_res.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e46fa17-14cb-4f8e-b765-674739ce784a",
   "metadata": {},
   "source": [
    "### sLLM-LLM 속도 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "caafdc42-26be-4b0d-b5b1-dda295307a8f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf8fedf242b14abb85f7f960c0c035cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/610 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd23c613b77e4e1ca5c653df8b8266ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/33.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "012708515e284cf0ac40311bebee76ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe151b52c7be433ca5aea988e841cd0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00003.safetensors:   0%|          | 0.00/9.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40c9a79e386044afb8fb146004917103",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00003.safetensors:   0%|          | 0.00/9.90G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ed6ad6048d4467991b996920fd188ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00003.safetensors:   0%|          | 0.00/6.18G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37cbca3c2b4e4b91a1d78ba728421b74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "875c61eee9de4f429a909ad83ab8135d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/188 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "llm_model_name = \"meta-llama/Llama-2-13b-hf\"\n",
    "llm = AutoModelForCausalLM.from_pretrained(llm_model_name, token=hf_token, device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d12ccb1d-950a-43e6-9899-138a09ae040b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explain the benefits of using LLM.\n",
      "The LLM is an optional course that is taught by a group of experienced and qualified teachers. The course is designed to help children develop their speaking and listening skills.\n",
      "The LLM is a great way to improve your child’s confidence and communication skills. The course is also a lot of fun and will help your child learn new things.\n",
      "The LLM is an excellent way to improve your child’s confidence and communication skills. The course is also a lot of fun and will help your child learn new things.\n",
      "The LLM is a great way to improve your child’s confidence and communication skills. The course is also a lot of fun and will help your child learn new things.\n",
      "The LLM is an optional course that is taught by a group of experienced and qualified teachers. The course is designed to help children develop their speaking and listening skills. The LLM is a great way to improve your child’s confidence and communication skills. The course is also a lot of fun and will help your child learn new things.\n",
      "The LLM is a great way to improve your child’s confidence and communication skills. The course is also a lot of fun and will help your child learn new things. The LLM is an optional course that is taught by a group of experienced and qualified teachers. The course is designed to help children develop their speaking and listening skills.\n",
      "The LLM is a great way to improve your child’s confidence and communication skills. The course is also a lot of fun and will help your child learn new things. The LLM is an optional course that is taught by a group of experienced and qualified teachers. The course is designed to help children develop their speaking and listening skills.\n",
      "The LLM is a great way to improve your child’s confidence and communication skills. The course is also a lot of fun and will help your child learn new things. The LLM is an optional course that is taught by a group of experienced and qualified teachers. The course is designed to help children develop their speaking and listening skills. The LLM is a great way to improve your child’s confidence and communication skills. The course is also a lot of fun and will help your child learn new things. The LLM is an optional course that is taught by a group of experienced and qualified teachers. The course is designed to help children develop their speaking and listening skills. The LLM is\n",
      "시간: 27.03초\n",
      "Explain the benefits of using LLM.\n",
      "List the main factors that influence the choice of LLM.\n",
      "List the different types of LLM.\n",
      "Describe the features of LLM.\n",
      "Describe the types of LLM.\n",
      "Explain the use of LLM.\n",
      "Explain the features of LLM.\n",
      "List the types of LLM.\n",
      "Describe the benefits of using LLM.\n",
      "Describe the main factors that influence the choice of LLM.\n",
      "Describe the features of LLM.\n",
      "Describe the use of LLM.\n",
      "List the main factors that influence the choice of LLM.\n",
      "Describe the different types of LLM.\n",
      "Describe the use of LLM\n",
      "List the different types of LLM\n",
      "Explain the use of LLM.\n",
      "Describe the types of LLM\n",
      "Describe the features of LLM\n",
      "Describe the benefits of using LLM\n",
      "List the types of LLM\n",
      "List the main factors that influence the choice of LLM\n",
      "Explain the benefits of using LLM\n",
      "Describe the features of LLM\n",
      "Describe the benefits of using LLM.\n",
      "Describe the main factors that influence the choice of LLM.\n",
      "Describe the features of LLM\n",
      "Describe the use of LLM.\n",
      "List the different types of LLM.\n",
      "Explain the use of LLM\n",
      "List the different types of LLM.\n",
      "Describe the different types of LLM\n",
      "Describe the features of LLM.\n",
      "Describe the benefits of using LLM.\n",
      "List the types of LLM.\n",
      "Describe the features of LLM.\n",
      "List the different types of LLM.\n",
      "Describe the different types of LLM.\n",
      "List the types of LLM.\n",
      "Describe the different types of LLM.\n",
      "Describe the main factors that influence the choice of LLM.\n",
      "Describe the features of LLM.\n",
      "Describe the benefits of using LLM.\n",
      "Describe the features of LLM.\n",
      "Describe the use of LLM.\n",
      "List the different types of LLM.\n",
      "Describe the features of LLM.\n",
      "Describe the use of LLM.\n",
      "Describe the main factors that influence the choice of LLM.\n",
      "Describe the features of LLM.\n",
      "Describe the benefits of using LLM.\n",
      "Describe the main factors that influence the choice of LLM\n",
      "시간: 47.33초\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "models = [sllm, llm]\n",
    "prompt = \"Explain the benefits of using LLM.\"\n",
    "\n",
    "for model in models:\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "    start_time = time.time()\n",
    "    output = model.generate(**inputs, max_length=500)\n",
    "    end_time = time.time()\n",
    "\n",
    "    model_res = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "    print(model_res)\n",
    "    print(f\"시간: {end_time - start_time:.2f}초\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f6c3c7-d344-475e-bd3a-02e269f051f8",
   "metadata": {},
   "source": [
    "### 응답 유지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd048063-5e95-412a-9373-3c6c44d9ddd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am planning a trip to Japan. What are the best cities to visit?\n",
      "Asked by Linda, South Africa\n",
      "Japan is a country of great diversity. The cities of Tokyo and Osaka are the best known. Tokyo is the economic and political centre of Japan, and has been the capital since 1603. Osaka is the second largest city in Japan, and is famous for its nightlife and food. Kyoto is also a major city in Japan, and is famous for its temples and gardens.\n",
      "I have never been to Japan before. What are the best places to visit?\n",
      "Asked by Diana, United States\n",
      "I have been to Japan many times. It is a beautiful country. I would recommend visiting Tokyo, Kyoto, and Osaka. Tokyo is the capital and the largest city in Japan. It is a modern city with many skyscrapers. Kyoto is the former capital of Japan, and is famous for its temples and gardens. Osaka is the second largest city in Japan, and is famous for its nightlife and food.\n",
      "What are the best places to visit in Japan?\n",
      "Asked by Eve, United States\n",
      "Japan is a beautiful country with many different places to visit. Some of the best places to visit include Tokyo, Kyoto, and Osaka. Tokyo is the capital of Japan and is a modern city with many skyscrapers. Kyoto is the former capital of Japan and is famous for its temples and gardens. Osaka is the second largest city in Japan and is famous for its nightlife and food.\n",
      "What are the best cities to visit in Japan?\n",
      "Asked by Jessica, United States\n",
      "Japan is a beautiful country with many different places to visit. Some of the best cities to visit in Japan include Tokyo, Kyoto, and Osaka. Tokyo is the capital of Japan and is a modern city with many skyscrapers. Kyoto is the former capital of Japan and is famous for its temples and gardens. Osaka is the second largest city in Japan and is famous for its nightlife and food.\n",
      "What are the best cities to visit in Japan?\n",
      "Asked by Melissa, United States\n",
      "Japan is a beautiful country with many different places to visit. Some of the best cities to visit in Japan include Tokyo,\n"
     ]
    }
   ],
   "source": [
    "prompt1 = \"I am planning a trip to Japan. What are the best cities to visit?\"\n",
    "\n",
    "inputs1 = tokenizer(prompt1, return_tensors=\"pt\").to(sllm.device)\n",
    "outputs1 = sllm.generate(**inputs1, max_length=500)\n",
    "response1 = tokenizer.decode(outputs1[0], skip_special_tokens=True)\n",
    "\n",
    "print(response1)\n",
    "\n",
    "# 일본 여행을 계획하고 있습니다. 방문하기 가장 좋은 도시는 어디인가요?\n",
    "# 남아프리카 공화국 린다의 질문\n",
    "# 일본은 다양성이 매우 풍부한 나라입니다. 도쿄와 오사카가 가장 잘 알려져 있습니다. 도쿄는 일본의 경제 및 정치 중심지이며 1603년부터 수도로 사용되어 왔습니다. 오사카는 일본에서 두 번째로 큰 도시이며 밤문화와 음식으로 유명합니다. 교토는 일본의 주요 도시이기도 하며 사찰과 정원으로 유명합니다.\n",
    "# 저는 일본에 한 번도 가본 적이 없습니다. 가장 좋은 방문지는 어디인가요?\n",
    "# 다이애나의 질문, 미국\n",
    "# 저는 일본에 여러 번 가본 적이 있습니다. 아름다운 나라입니다. 도쿄, 교토, 오사카를 방문하는 것을 추천합니다. 도쿄는 일본의 수도이자 가장 큰 도시입니다. 고층 빌딩이 많은 현대적인 도시입니다. 교토는 일본의 옛 수도이자 사원과 정원으로 유명합니다. 오사카는 일본에서 두 번째로 큰 도시이며, 밤문화와 음식으로 유명합니다.\n",
    "# 일본에서 가장 좋은 방문지는 어디인가요?\n",
    "# 이브의 질문, 미국\n",
    "# 일본은 다양한 방문지가 많은 아름다운 나라입니다. 방문하기 가장 좋은 곳으로는 도쿄, 교토, 오사카가 있습니다. 도쿄는 일본의 수도이자 고층 빌딩이 많은 현대 도시입니다. 교토는 일본의 옛 수도이자 사원과 정원으로 유명합니다. 오사카는 일본에서 두 번째로 큰 도시이며 밤문화와 음식으로 유명합니다.\n",
    "# 일본에서 방문하기 가장 좋은 도시는 어디인가요?\n",
    "# 제시카의 질문, 미국\n",
    "# 일본은 방문할 곳이 많은 아름다운 나라입니다. 일본에서 방문하기 가장 좋은 도시로는 도쿄, 교토, 오사카가 있습니다. 도쿄는 일본의 수도이자 고층 빌딩이 많은 현대 도시입니다. 교토는 일본의 옛 수도이자 사원과 정원으로 유명합니다. 오사카는 일본에서 두 번째로 큰 도시이며 밤문화와 음식으로 유명합니다.\n",
    "# 일본에서 방문하기 가장 좋은 도시는 어디인가요?\n",
    "# 멜리사의 질문, 미국\n",
    "# 일본은 방문할 수 있는 다양한 장소가 있는 아름다운 나라입니다. 일본에서 방문하기 가장 좋은 도시로는 도쿄가 있습니다,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f41b43d-f85f-494d-a00f-0ab62e2ffa20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What local foods should I try in those cities?\n",
      "Food is a huge part of traveling, and no matter where you go, you’ll find that the locals love their food. But what foods should you try in those cities?\n",
      "Food is a huge part of traveling, and no matter where you go, you’ll find that the locals love their food. But what foods should you try in those cities? Here are some of the best foods to try in each city.\n",
      "What local foods should I try in those cities? There are many different foods that you should try when visiting different cities. Here are some of the best local foods to try in each city:\n",
      "In New York City, you should try the famous pizza. There are many different types of pizza, and each one is delicious. You should also try the famous bagels. They are very popular in New York City, and they are delicious.\n",
      "In Los Angeles, you should try the famous In-N-Out Burger. It is a fast food restaurant that is very popular in Los Angeles. You should also try the famous tacos. They are very popular in Los Angeles, and they are delicious.\n",
      "In San Francisco, you should try the famous sourdough bread. It is a type of bread that is very popular in San Francisco. You should also try the famous chowder. It is a type of soup that is very popular in San Francisco.\n",
      "In Las Vegas, you should try the famous buffets. They are very popular in Las Vegas, and they are delicious. You should also try the famous shrimp cocktail. It is a type of appetizer that is very popular in Las Vegas.\n",
      "In Miami, you should try the famous Cuban food. It is a type of food that is very popular in Miami. You should also try the famous Miami Vice. It is a type of sandwich that is very popular in Miami.\n",
      "In Orlando, you should try the famous Disney World food. It is a type of food that is very popular in Orlando. You should also try the famous Universal Studios food. It is a type of food that is very popular in Orlando.\n",
      "In Chicago, you should try the famous Chicago-style pizza. It is a type of pizza that is very popular\n"
     ]
    }
   ],
   "source": [
    "prompt2 = \"What local foods should I try in those cities?\"\n",
    "\n",
    "inputs2 = tokenizer(prompt2, return_tensors=\"pt\").to(sllm.device)\n",
    "outputs2 = sllm.generate(**inputs2, max_length=500)\n",
    "response2 = tokenizer.decode(outputs2[0], skip_special_tokens=True)\n",
    "\n",
    "print(response2)\n",
    "\n",
    "# 그 도시들에서 어떤 현지 음식을 먹어봐야 할까요?\n",
    "# 음식은 여행의 큰 부분을 차지하며, 어디를 가든 현지인들이 음식을 좋아한다는 것을 알 수 있습니다. 하지만 그 도시에서 어떤 음식을 먹어봐야 할까요?\n",
    "# 음식은 여행의 큰 부분을 차지하며, 어디를 가든 현지인들이 음식을 좋아한다는 것을 알 수 있습니다. 하지만 이러한 도시에서 어떤 음식을 먹어봐야 할까요? 각 도시에서 먹어볼 수 있는 최고의 음식은 다음과 같습니다.\n",
    "# 그 도시들에서는 어떤 지역 음식을 먹어봐야 하나요? 다양한 도시를 방문할 때 먹어봐야 할 다양한 음식이 있습니다. 각 도시에서 먹어볼 수 있는 최고의 지역 음식은 다음과 같습니다:\n",
    "# 뉴욕에서는 유명한 피자를 먹어봐야 합니다. 피자의 종류는 다양하며 각 피자는 맛있습니다. 유명한 베이글도 먹어봐야 합니다. 뉴욕에서 매우 인기가 많고 맛있습니다.\n",
    "# 로스앤젤레스에서는 유명한 인앤아웃 버거를 드셔보세요. 로스앤젤레스에서 매우 인기 있는 패스트푸드점입니다. 유명한 타코도 드셔보세요. 로스앤젤레스에서 매우 인기가 많고 맛있습니다.\n",
    "# 샌프란시스코에서는 유명한 사워도우 빵을 먹어봐야 합니다. 샌프란시스코에서 매우 인기 있는 빵 종류입니다. 유명한 차우더도 먹어봐야 합니다. 샌프란시스코에서 매우 인기 있는 수프 종류입니다.\n",
    "# 라스베이거스에서는 유명한 뷔페를 먹어봐야 합니다. 라스베이거스에서 매우 인기 있고 맛있습니다. 유명한 새우 칵테일도 드셔보세요. 라스베이거스에서 매우 인기 있는 애피타이저의 일종입니다.\n",
    "# 마이애미에서는 유명한 쿠바 음식을 먹어봐야 합니다. 마이애미에서 매우 인기 있는 음식입니다. 마이애미 바이스도 먹어봐야 합니다. 마이애미에서 매우 인기 있는 샌드위치 종류입니다.\n",
    "# 올랜도에서는 유명한 디즈니 월드 음식을 먹어봐야 합니다. 올랜도에서 매우 인기 있는 음식입니다. 유니버설 스튜디오의 유명한 음식도 먹어봐야 합니다. 올랜도에서 매우 인기 있는 음식입니다.\n",
    "# 시카고에서는 유명한 시카고 스타일의 피자를 드셔보세요. 매우 인기 있는 피자 종류입니다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a101043f-9dfb-4e6c-a7d4-bc778a1d65a0",
   "metadata": {},
   "source": [
    "### 다국어 처리 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2fe0c9be-1ca6-41e2-8a53-5d0c68376f22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79bdd265b3de4e428cd07899da8e588d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device because they were offloaded to the cpu.\n",
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "multilingual_model = pipeline(\"text-generation\", model=\"meta-llama/Llama-2-7b-hf\", device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bc3cda5c-4f45-4d9b-b706-b949cdfd9fff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== English ===\n",
      "Translate 'Hello, how are you?' to French. I am in a conversation with a Frenchman and I want to say hello to him.\n",
      "Translate 'How are you?' to French. I want to say hello to a Frenchman and I want to ask him how he is.\n",
      "Translate 'I am well' to French. I want to say hello to a Frenchman and I want to tell him that I am doing well.\n",
      "Translate 'I am fine\n",
      "\n",
      "=== Korean ===\n",
      "안녕하세요. 오늘 날씨가 어때요? 행복한 날씨입니다. 여러분 함께 배운 말 몇 가지 말씀드립니다.\n",
      "Hello. How is the\n",
      "\n",
      "=== Japanese ===\n",
      "こんにちは。天気はどうですか？ なんといっても、天気は晴れているよね。 こんにちは。どうですか？ なんといっても、天気は晴れているよね。 こんにちは。どうですか？ なんといっても、天気は�\n"
     ]
    }
   ],
   "source": [
    "prompts = {\n",
    "    \"English\": \"Translate 'Hello, how are you?' to French.\",\n",
    "    \"Korean\": \"안녕하세요. 오늘 날씨가 어때요?\",\n",
    "    \"Japanese\": \"こんにちは。天気はどうですか？\"\n",
    "}\n",
    "\n",
    "for lang, prompt in prompts.items():\n",
    "    response = multilingual_model(prompt, max_length=100)\n",
    "    print(f\"\\n=== {lang} ===\")\n",
    "    print(response[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a644c75",
   "metadata": {},
   "source": [
    "- '안녕하세요, 잘 지내세요?'를 프랑스어로 번역하세요. 저는 한 프랑스인과 대화 중인데 그에게 인사하고 싶습니다.\n",
    "- '어떻게 지내세요?'를 프랑스어로 번역하세요. 프랑스인에게 인사하고 싶고, 그에게 안부를 묻고 싶습니다.\n",
    "- '나는 잘 지내고 있다'를 프랑스어로 번역하세요. 프랑스인에게 인사하고 싶고 잘 지내고 있다고 전하고 싶습니다.\n",
    "- '나는 괜찮아'를 번역합니다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ebbb4b",
   "metadata": {},
   "source": [
    "- 안녕하세요 날씨는 어떤가요? 뭐니뭐니해도 날씨는 맑지. 안녕하세요 어때요? 뭐니뭐니해도 날씨는 맑지. 안녕하세요 어때요? 뭐니뭐니해도, 날씨는"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
