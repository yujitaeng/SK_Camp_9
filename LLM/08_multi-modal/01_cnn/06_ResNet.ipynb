{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMWZJrmoYNEugmAX9zG583r"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# ResNet"],"metadata":{"id":"ZjImgt8ST3Ih"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn"],"metadata":{"id":"svNXtZtLUPSW","executionInfo":{"status":"ok","timestamp":1742539664296,"user_tz":-540,"elapsed":11428,"user":{"displayName":"남윤진","userId":"10096486385946148318"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","execution_count":2,"metadata":{"id":"hKMhRRraTKdu","executionInfo":{"status":"ok","timestamp":1742539664299,"user_tz":-540,"elapsed":8,"user":{"displayName":"남윤진","userId":"10096486385946148318"}}},"outputs":[],"source":["class IdentityBlock(nn.Module):\n","  def __init__(self, in_channels, mid_kernel_size, filters):\n","    super(IndentityBlock, self).__init__()\n","    filter1, filter2, filter3 = filters\n","\n","    self.conv1 = nn.Conv2d(in_channels, filter1, kernel_size=1, padding=0)\n","    self.bn1 = nn.BatchNorm2d(filter1)\n","    self.relu1 = nn.ReLU(inplace=True)\n","\n","    self.conv2 = nn.Conv2d(filter1, filter2, kernel_size=mid_kernel_size, padding=mid_kernel_size//2)\n","    self.bn2 = nn.BatchNorm2d(filter2)\n","    self.relu2 = nn.ReLU(inplace=True)\n","\n","    self.conv3 = nn.Conv2d(filter2, filter3, kernel_size=1, padding=0)\n","    self.bn3 = nn.BatchNorm2d(filter3)\n","    self.relu_out = nn.ReLU(inplace=True)\n","\n","  def forward(self, x):\n","\n","    identity = x\n","\n","    out = self.conv1(x)\n","    out = self.bn1(out)\n","    out = self.relu1(out)\n","\n","    out = self.conv2(out)\n","    out = self.bn2(out)\n","    out = self.relu2(out)\n","\n","    out = self.conv3(x)\n","    out = self.bn3(out)\n","\n","    out += identity\n","\n","    out = self.relu_out(out)\n","    return out"]},{"cell_type":"code","source":["import torch.nn.functional as F\n","\n","class ConvolutionalBlock(nn.Module):\n","  def __init__(self, in_channels, mid_kernel_size, filters):\n","    super(ConvolutionalBlock, self).__init__()\n","    filter1, filter2, filter3 = filters\n","\n","    self.conv1 = nn.Conv2d(in_channels, filter1, kernel_size=1, stride=2)\n","    self.bn1 = nn.BatchNorm2d(filter1)\n","\n","    self.conv2 = nn.Conv2d(filter1, filter2, kernel_size=mid_kernel_size, padding=mid_kernel_size//2)\n","    self.bn2 = nn.BatchNorm2d(filter2)\n","\n","    self.conv3 = nn.Conv2d(filter2, filter3, kernel_size=1, stride=2)\n","    self.bn3 = nn.BatchNorm2d(filter3)\n","\n","    self.shortcut_conv = nn.Conv2d(in_channels, filter3, kernel_size=1, stride=2)\n","    self.shortcut_bn = nn.BatchNorm2d(filter3)\n","\n","  def forward(self, x):\n","    shortcut = self.shortcut_bn(self.shortcut_conv(x))\n","\n","    out = F.relu(self.bn1(self.conv1(x)))\n","    out = F.relu(self.bn2(self.conv2(out)))\n","    out = self.bn3(self.conv3(out))\n","\n","    out += shortcut\n","    out = F.relu(out)\n","    return out"],"metadata":{"id":"po75b0AuT_ax","executionInfo":{"status":"ok","timestamp":1742539664301,"user_tz":-540,"elapsed":7,"user":{"displayName":"남윤진","userId":"10096486385946148318"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["class ResNet(nn.Module):\n","  def __init__(self):\n","    super(ResNet, self).__init__()\n","\n","    self.stage0 = nn.Sequential(\n","        nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3),  # (224,224,3) -> (112,112,64)\n","        nn.BatchNorm2d(64),\n","        nn.ReLU(inplace=True),\n","        nn.MaxPool2d(kernel_size=3, stride=2, padding=1)  # (56,56,64)\n","    )\n","\n","    self.stage1 = nn.Sequential(\n","        ConvolutionalBlock(64, 3, (64, 64, 256), strides=1),\n","        IdentityBlock(256, 3, (64, 64, 256)),\n","        IdentityBlock(256, 3, (64, 64, 256))\n","    )\n","\n","    self.stage2 = nn.Sequential(\n","        ConvolutionalBlock(256, 3, (128, 128, 512), strides=2),\n","        IdentityBlock(512, 3, (128, 128, 512)),\n","        IdentityBlock(512, 3, (128, 128, 512)),\n","        IdentityBlock(512, 3, (128, 128, 512))\n","    )\n","\n","    self.stage3 = nn.Sequential(\n","        ConvolutionalBlock(512, 3, (256, 256, 1024), strides=2),\n","        IdentityBlock(1024, 3, (256, 256, 1024)),\n","        IdentityBlock(1024, 3, (256, 256, 1024)),\n","        IdentityBlock(1024, 3, (256, 256, 1024)),\n","        IdentityBlock(1024, 3, (256, 256, 1024)),\n","        IdentityBlock(1024, 3, (256, 256, 1024))\n","    )\n","\n","    self.stage4 = nn.Sequential(\n","        ConvolutionalBlock(1024, 3, (512, 512, 2048), strides=2),\n","        IdentityBlock(2048, 3, (512, 512, 2048)),\n","        IdentityBlock(2048, 3, (512, 512, 2048))\n","    )\n","\n","    self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n","    self.dropout1 = nn.Dropout(0.5)\n","    self.fc1 = nn.Linear(2048, 500)\n","    self.dropout2 = nn.Dropout(0.5)\n","    self.fc2 = nn.Linear(500, 1000)\n","\n","  def forward(self, x):\n","    x = self.stage0(x)\n","    x = self.stage1(x)\n","    x = self.stage2(x)\n","    x = self.stage3(x)\n","    x = self.stage4(x)\n","    x = self.avgpool(x)\n","    x = torch.flatten(x, 1)\n","    x = self.dropout1(x)\n","    x = F.relu(self.fc1(x))\n","    x = self.dropout2(x)\n","    x = self.fc2(x)\n","    x = F.softmax(x, dim=1)\n","    return x"],"metadata":{"id":"Num58SmpUDyz","executionInfo":{"status":"ok","timestamp":1742539775673,"user_tz":-540,"elapsed":47,"user":{"displayName":"남윤진","userId":"10096486385946148318"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["# 사전학습 모델 로드"],"metadata":{"id":"EBYSf190bHiW"}},{"cell_type":"code","source":["import torchvision.models as models"],"metadata":{"id":"wWBuxvlEbfjl","executionInfo":{"status":"ok","timestamp":1742539789711,"user_tz":-540,"elapsed":11152,"user":{"displayName":"남윤진","userId":"10096486385946148318"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# VGG\n","vgg_model = models.vgg16(pretrained=True)\n","\n","# ResNet\n","resnet_model = models.resnet50(pretrained=True)\n","\n","# Inception\n","inception_model = models.inception_v3(pretrained=True, aux_logits=True)\n","\n","# MobileNet\n","mobilenet_model = models.mobilenet_v2(weights=models.MobileNet_V2_Weights.DEFAULT)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OIuBixAbbJtJ","executionInfo":{"status":"ok","timestamp":1742539804065,"user_tz":-540,"elapsed":14350,"user":{"displayName":"남윤진","userId":"10096486385946148318"}},"outputId":"e7823043-42f5-4a80-948f-ca47499e9d77"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n","100%|██████████| 528M/528M [00:08<00:00, 62.5MB/s]\n","/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n","100%|██████████| 97.8M/97.8M [00:00<00:00, 146MB/s]\n","/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Inception_V3_Weights.IMAGENET1K_V1`. You can also use `weights=Inception_V3_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/inception_v3_google-0cc3c7bd.pth\" to /root/.cache/torch/hub/checkpoints/inception_v3_google-0cc3c7bd.pth\n","100%|██████████| 104M/104M [00:00<00:00, 131MB/s]\n","Downloading: \"https://download.pytorch.org/models/mobilenet_v2-7ebf99e0.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v2-7ebf99e0.pth\n","100%|██████████| 13.6M/13.6M [00:00<00:00, 87.8MB/s]\n"]}]}]}