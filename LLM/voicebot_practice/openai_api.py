import streamlit as st
import speech_recognition as sr
from gtts import gTTS
import os
import tempfile
import base64
import openai
from dotenv import load_dotenv

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")

# ìŒì„± ì¸ì‹ í•¨ìˆ˜
def speech_to_text():
    r = sr.Recognizer()
    with sr.Microphone() as source:
        st.write("ë§ì”€í•´ì£¼ì„¸ìš”...")
        audio = r.listen(source)
    try:
        text = r.recognize_google(audio, language="ko-KR")
        return text
    except sr.UnknownValueError:
        return "ìŒì„±ì„ ì¸ì‹í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
    except sr.RequestError:
        return "ìŒì„± ì¸ì‹ ì„œë¹„ìŠ¤ì— ì ‘ê·¼í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

# GPT-4o-minië¥¼ ì´ìš©í•œ ì‘ë‹µ ìƒì„± í•¨ìˆ˜
def generate_response(prompt):
    client = openai.OpenAI()
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {"role": "system", "content": "ë‹¹ì‹ ì€ ì¹œì ˆí•˜ê³  ë„ì›€ì´ ë˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤."},
            {"role": "user", "content": prompt}
        ]
    )
    return response.choices[0].message.content

# í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜
def text_to_speech(text):
    fd, temp_path = tempfile.mkstemp(suffix=".mp3")
    try:
        tts = gTTS(text=text, lang='ko')
        tts.save(temp_path)
        with open(temp_path, 'rb') as f:
            data = f.read()
            b64 = base64.b64encode(data).decode()
            audio_tag = f'<audio autoplay="true" src="data:audio/mp3;base64,{b64}">'
        return audio_tag
    finally:
        os.close(fd)
        try:
            os.unlink(temp_path)
        except PermissionError:
            pass  # íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨ ì‹œ ë¬´ì‹œ

# Streamlit ì•± ì‹œì‘
st.set_page_config(page_title="ìŒì„± ëŒ€í™”í˜• AI ì±—ë´‡", page_icon="ğŸ™ï¸", layout="wide")

st.title("ğŸ—£ï¸ ìŒì„± ëŒ€í™”í˜• AI ì±—ë´‡")

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if 'messages' not in st.session_state:
    st.session_state.messages = []

# 3ë¶„í•  ë ˆì´ì•„ì›ƒ ìƒì„± (2:1 ë¹„ìœ¨)
col1, col2 = st.columns([2, 1])

with col1:
    st.subheader("ğŸ’¬ ì‹¤ì‹œê°„ ëŒ€í™”")
    # ìŒì„± ì…ë ¥ ë²„íŠ¼
    if st.button("ğŸ¤ ìŒì„±ìœ¼ë¡œ ì§ˆë¬¸í•˜ê¸°"):
        user_input = speech_to_text()
        st.session_state.messages.append({"role": "user", "content": user_input})
        st.write(f"ğŸ‘¤ ì‚¬ìš©ì: {user_input}")

        # AI ì‘ë‹µ ìƒì„±
        ai_response = generate_response(user_input)
        st.session_state.messages.append({"role": "assistant", "content": ai_response})
        st.write(f"ğŸ¤– AI: {ai_response}")

        # AI ì‘ë‹µì„ ìŒì„±ìœ¼ë¡œ ì¶œë ¥
        audio_tag = text_to_speech(ai_response)
        st.markdown(audio_tag, unsafe_allow_html=True)

with col2:
    st.subheader("ğŸ“œ ëŒ€í™” ê¸°ë¡")
    for message in st.session_state.messages:
        if message['role'] == 'user':
            st.markdown(f"ğŸ‘¤ **ì‚¬ìš©ì**: {message['content']}")
        else:
            st.markdown(f"ğŸ¤– **AI**: {message['content']}")

# ìŠ¤íƒ€ì¼ ì ìš©
st.markdown("""
<style>
    .stButton>button {
        background-color: #ff6a13;
        color: white;
        font-size: 18px;
        padding: 10px 24px;
        border-radius: 12px;
    }
    .stAudio {
        margin-top: 20px;
    }
    .css-1d391kg {
        padding-right: 1rem;
    }
</style>
""", unsafe_allow_html=True)
