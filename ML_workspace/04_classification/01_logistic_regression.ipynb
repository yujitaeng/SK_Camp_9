{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 분류 (Classification)\n",
    "- 입력 데이터를 미리 정의된 여러 클래스 중 하나로 예측하는 것 (범주형 데이터)\n",
    "    - 이진 분류: 양성(1), 음성(0) 중에 하나를 맞추는 것\n",
    "    - 다중 분류: 여러 클래스 중 하나를 맞추는 것"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "- 선형 회귀 방식으로 분류 문제를 해결하는 모델\n",
    "    - 이진 분류: 이진 분류를 위한 로지스틱 함수(시그모이드)를 통해 확률값을 계산하고 0 또는 1로 분류\n",
    "    - 다중 분류: 다중 분류를 위한 소프트맥스 함수를 통해 각 클래스별 확률값을 계산해 다중 분류"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**하이퍼 파라미터**\n",
    "\n",
    "<table>\n",
    "  <thead>\n",
    "    <tr>\n",
    "      <th>하이퍼파라미터</th>\n",
    "      <th>설명</th>\n",
    "      <th>기본값</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <td><code>penalty</code></td>\n",
    "      <td>정규화의 종류 지정 / <code>'l1'</code>, <code>'l2'</code>, <code>'elasticnet'</code>, <code>'none'</code> 중 선택</td>\n",
    "      <td><code>'l2'</code></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td><code>C</code></td>\n",
    "      <td>정규화의 강도를 제어 / 값이 작을수록 강한 정규화 적용 (<code>1 / λ</code>로 해석 가능)</td>\n",
    "      <td><code>1.0</code></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td><code>solver</code></td>\n",
    "      <td>최적화 알고리즘 선택 / <code>'newton-cg'</code>, <code>'lbfgs'</code>, <code>'liblinear'</code>, <code>'sag'</code>, <code>'saga'</code> 중 선택</td>\n",
    "      <td><code>'lbfgs'</code></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td><code>max_iter</code></td>\n",
    "      <td>최적화를 위한 최대 반복 횟수</td>\n",
    "      <td><code>100</code></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td><code>multi_class</code></td>\n",
    "      <td>다중 클래스 문제에서 사용할 전략 / <code>'auto'</code>, <code>'ovr'</code> (one-vs-rest), <code>'multinomial'</code> 중 선택</td>\n",
    "      <td><code>'auto'</code></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td><code>fit_intercept</code></td>\n",
    "      <td>절편을 학습할지 여부 / <code>True</code> 또는 <code>False</code></td>\n",
    "      <td><code>True</code></td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**solver**\n",
    "\n",
    "<table>\n",
    "  <thead>\n",
    "    <tr>\n",
    "      <th>Solver</th>\n",
    "      <th>설명</th>\n",
    "      <th>특징</th>\n",
    "      <th>추천 사용 상황</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <td><strong>liblinear</strong></td>\n",
    "      <td>선형 분류를 위한 라이브러리인 \"LIBLINEAR\"에서 유래, 작은 데이터셋이나 희소 데이터셋에 적합한 이중 좌표축 감소법(Dual Coordinate Descent Algorithm) 사용</td>\n",
    "      <td>빠르고 메모리 효율적이며, L1 및 L2 정규화 모두를 지원</td>\n",
    "      <td>작은 크기의 데이터셋, 희소한 피처를 가진 데이터셋</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td><strong>newton-cg</strong></td>\n",
    "      <td>Newton Conjugate Gradient 뉴턴법을 사용한 최적화 알고리즘, 큰 데이터셋에서도 효율적으로 동작</td>\n",
    "      <td>L2 정규화를 지원하며, 대규모 데이터셋에 적합</td>\n",
    "      <td>중대형 크기의 데이터셋</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td><strong>lbfgs</strong></td>\n",
    "      <td>Broyden-Fletcher-Goldfarb-Shanno(BFGS) 알고리즘의 변형인 L-BFGS(Limited-memory Broyden–Fletcher–Goldfarb–Shanno) 알고리즘을 사용</td>\n",
    "      <td>L2 정규화를 지원하며, 메모리를 절약하면서도 효율적인 성능을 발휘</td>\n",
    "      <td>대규모 데이터셋, 다중 클래스 분류</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td><strong>sag</strong></td>\n",
    "      <td>Stochastic Average Gradient 하강법으로, 점진적으로 평균 그래디언트를 사용하여 최적화</td>\n",
    "      <td>매우 큰 데이터셋에서 효율적이며, L2 정규화를 지원</td>\n",
    "      <td>매우 큰 크기의 데이터셋</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td><strong>saga</strong></td>\n",
    "      <td>Stochastic Average Gradient Augmented / sag의 확장판으로, L1 및 L2 정규화 모두를 지원</td>\n",
    "      <td>희소 데이터셋에도 적합하며, 매우 큰 데이터셋에서 효율적</td>\n",
    "      <td>매우 큰 크기의 데이터셋, 희소한 피처를 가진 데이터셋</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 이진 분류를 위한 Sigmoid 함수\n",
    "- 선형회귀식을 통해 도출한 예측값(z)을 0과 1 사이의 수로 변환해주는 활성화 함수(Activation Function)\n",
    "\n",
    "$\n",
    "    시그모이드(z) = \\frac{1}{1 + e^{-z}}\n",
    "$\n",
    "\n",
    "![](https://d.pr/i/tTdKdt+)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시그모이드 시각화\n",
    "z = np.linspace(-5, 5, 100)    # 선형회귀 결과값\n",
    "sigmoid_value = 1 / (1 + np.exp(-z))\n",
    "\n",
    "plt.plot(z, sigmoid_value)\n",
    "plt.xlabel('z')\n",
    "plt.ylabel('sigmoid(z)')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 도미, 빙어 데이터셋 준비\n",
    "fish_df = pd.read_csv('./data/fish.csv')\n",
    "# fish_df['Species'].value_counts()\n",
    "is_bream_or_smelt = (fish_df['Species'] == 'Bream') | (fish_df['Species'] == 'Smelt')\n",
    "fish_df = fish_df[is_bream_or_smelt]\n",
    "fish_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 분리 및 정규화\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X = fish_df.drop('Species', axis=1)\n",
    "y = fish_df['Species']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 학습 및 평가\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_clf = LogisticRegression()\n",
    "lr_clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "lr_clf.score(X_train_scaled, y_train), lr_clf.score(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lr_clf.predict(X_test_scaled[:3])    # 예측\n",
    "y_pred    # ['Bream', 'Smelt', 'Smelt']\n",
    "\n",
    "print(lr_clf.classes_)    # 분류 카테고리\n",
    "lr_clf.predict_proba(X_test_scaled[:3])    # 클래스별 확률"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가중치, 절편\n",
    "lr_clf.coef_, lr_clf.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w1x1 + w2x2 + w3x3 + w4x4 + w5x5 + b\n",
    "\n",
    "# 선형회귀값 직접 계산\n",
    "z1 = np.dot(X_test_scaled[:3], lr_clf.coef_[0]) + lr_clf.intercept_\n",
    "\n",
    "# 선형회귀값 계산 함수 decision_function\n",
    "z2 = lr_clf.decision_function(X_test_scaled[:3])\n",
    "\n",
    "z1, z2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시그모이드 함수 적용\n",
    "sigmoid_value = 1 / (1 + np.exp(-z1))\n",
    "sigmoid_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최종 결과\n",
    "['Smelt' if value >= 0.5 else 'Bream' for value in sigmoid_value]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 다중 분류를 위한 Softmax 함수\n",
    "- 다중 클래스 분류를 위한 활성화 함수로 각 클래스에 대한 확률값 계산\n",
    "- k 개의 클래스가 존재할 때 주어진 입력에 대해 다음과 같이 계산\n",
    "\n",
    "$\n",
    "    softmax(z_i) = \\frac{e^{z_k}}{\\sum_{j=1}^{K} e^{z_j}}\n",
    "$\n",
    "\n",
    "- $z_k$ : 각 클래스에 대한 점수 (입력값)\n",
    "- $e^{z_k}$ : 해당 점수에 대한 지수 함수 적용\n",
    "- $\\sum_{j=1}^{K} e^{z_j}$ : 모든 클래스 점수에 대해 지수 함수 적용 후 총합"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**다중 클래스 확률 계산 순서**\n",
    "1. 샘플에 대한 회귀 결과 z 계산\n",
    "2. 소프트맥스 함수 적용\n",
    "    - z를 e의 지수로 적용해 값을 확대 (클래스별 z의 차이를 극대화)\n",
    "    - 합을 각 클래스의 값으로 나눠 비율을 계산하고 반환\n",
    "3. 가장 높은 확률 값을 가진 클래스 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat1</th>\n",
       "      <th>feat2</th>\n",
       "      <th>feat3</th>\n",
       "      <th>feat4</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.437839</td>\n",
       "      <td>-1.151891</td>\n",
       "      <td>-0.808298</td>\n",
       "      <td>0.947384</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.243953</td>\n",
       "      <td>-2.665636</td>\n",
       "      <td>-0.525755</td>\n",
       "      <td>-2.794481</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.403298</td>\n",
       "      <td>2.788787</td>\n",
       "      <td>1.368632</td>\n",
       "      <td>0.520942</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.572492</td>\n",
       "      <td>-0.395373</td>\n",
       "      <td>-0.576904</td>\n",
       "      <td>-1.502189</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.785067</td>\n",
       "      <td>-2.013302</td>\n",
       "      <td>0.366598</td>\n",
       "      <td>0.779589</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>1.650580</td>\n",
       "      <td>-1.108798</td>\n",
       "      <td>-0.718444</td>\n",
       "      <td>-0.227124</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>-0.499463</td>\n",
       "      <td>0.453598</td>\n",
       "      <td>1.179440</td>\n",
       "      <td>-2.068572</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.456127</td>\n",
       "      <td>-0.262591</td>\n",
       "      <td>-0.827231</td>\n",
       "      <td>-3.515597</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>2.418974</td>\n",
       "      <td>-1.309900</td>\n",
       "      <td>0.012592</td>\n",
       "      <td>-0.052393</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>-2.177197</td>\n",
       "      <td>-1.297552</td>\n",
       "      <td>-1.304470</td>\n",
       "      <td>1.461035</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       feat1     feat2     feat3     feat4  target\n",
       "0   1.437839 -1.151891 -0.808298  0.947384       1\n",
       "1  -1.243953 -2.665636 -0.525755 -2.794481       2\n",
       "2  -2.403298  2.788787  1.368632  0.520942       1\n",
       "3  -0.572492 -0.395373 -0.576904 -1.502189       2\n",
       "4  -0.785067 -2.013302  0.366598  0.779589       2\n",
       "..       ...       ...       ...       ...     ...\n",
       "95  1.650580 -1.108798 -0.718444 -0.227124       0\n",
       "96 -0.499463  0.453598  1.179440 -2.068572       2\n",
       "97  0.456127 -0.262591 -0.827231 -3.515597       0\n",
       "98  2.418974 -1.309900  0.012592 -0.052393       1\n",
       "99 -2.177197 -1.297552 -1.304470  1.461035       2\n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터셋 생성\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X, y = make_classification(     # 분류 문제 연습을 위한 가상 데이터셋 생성 함수\n",
    "    n_samples=100,       # 샘플 개수\n",
    "    n_features=4,        # 전체 특성 개수\n",
    "    n_informative=3,     # 유의미한 특성 개수\n",
    "    n_redundant=0,       # 중복 특성 개수\n",
    "    n_classes=3,         # 클래스 수\n",
    "    random_state=42      # 랜덤 시드\n",
    ")\n",
    "\n",
    "df = pd.DataFrame(X, columns=['feat1', 'feat2', 'feat3', 'feat4'])\n",
    "df['target'] = y\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 분리\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7066666666666667, 0.44)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 학습 및 평가\n",
    "lr_clf = LogisticRegression(max_iter=1000)\n",
    "lr_clf.fit(X_train, y_train)\n",
    "lr_clf.score(X_train, y_train), lr_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 2])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예측 (분류)\n",
    "y_pred = lr_clf.predict(X_test[:5])\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.22917118, 0.39960169, 0.37122713],\n",
       "        [0.83550691, 0.16166581, 0.00282727],\n",
       "        [0.573597  , 0.32484717, 0.10155583],\n",
       "        [0.20188375, 0.64427073, 0.15384551],\n",
       "        [0.02755811, 0.07287149, 0.8995704 ]]),\n",
       " array([1., 1., 1., 1., 1.]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict_proba = 클래스별 분류에 대한 확률 = softmax 함수 적용 결과\n",
    "# 모든 확률의 합은 1\n",
    "y_pred_proba = lr_clf.predict_proba(X_test[:5])\n",
    "y_pred_proba, y_pred_proba.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3, 4), (3,))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 직접 계산\n",
    "W = lr_clf.coef_\n",
    "B = lr_clf.intercept_\n",
    "W.shape, B.shape    # ((3, 4) = (클래스수, 특성수), (3,) = (클래스수))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.34611464,  0.20988442,  0.13623022],\n",
       "       [ 2.44374453,  0.80123723, -3.24498176],\n",
       "       [ 0.76663021,  0.19805797, -0.96468818],\n",
       "       [-0.29622795,  0.86419902, -0.56797107],\n",
       "       [-1.48600708, -0.51360637,  1.99961345]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 결정함수 (선형회귀값 계산)\n",
    "Z = lr_clf.decision_function(X_test[:5])\n",
    "Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.22917118, 0.39960169, 0.37122713],\n",
       "       [0.83550691, 0.16166581, 0.00282727],\n",
       "       [0.573597  , 0.32484717, 0.10155583],\n",
       "       [0.20188375, 0.64427073, 0.15384551],\n",
       "       [0.02755811, 0.07287149, 0.8995704 ]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# softmax 함수\n",
    "def softmax(z):\n",
    "    exp_z = np.exp(z)\n",
    "    sum_exp_z = np.sum(exp_z, axis=1, keepdims=True)\n",
    "    # print(exp_z, sum_exp_z)\n",
    "    return exp_z / sum_exp_z\n",
    "\n",
    "y_pred_proba = softmax(Z)\n",
    "y_pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum 함수 주의사항\n",
    "n = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "exp_n = np.exp(n)\n",
    "# keepdims=False -> (2,) : 차원 축소\n",
    "# keepdims=True -> (2, 1) : 차원 유지\n",
    "sum_exp_n = np.sum(exp_n, axis=1, keepdims=True)\n",
    "print(exp_n)\n",
    "print(sum_exp_n)\n",
    "print(exp_n / sum_exp_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.22917118, 0.39960169, 0.37122713],\n",
       "       [0.83550691, 0.16166581, 0.00282727],\n",
       "       [0.573597  , 0.32484717, 0.10155583],\n",
       "       [0.20188375, 0.64427073, 0.15384551],\n",
       "       [0.02755811, 0.07287149, 0.8995704 ]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scipy의 softmax 함수\n",
    "import scipy\n",
    "y_pred_proba = scipy.special.softmax(Z, axis=1)\n",
    "y_pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 2])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = np.argmax(y_pred_proba, axis=1)\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 다중 생선 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Species', 'Weight', 'Length', 'Diagonal', 'Height', 'Width'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Species\n",
       "Perch        56\n",
       "Bream        35\n",
       "Roach        20\n",
       "Pike         17\n",
       "Smelt        14\n",
       "Parkki       11\n",
       "Whitefish     6\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 로드 ./data/fish.csv\n",
    "fish_df = pd.read_csv('./data/fish.csv')\n",
    "print(fish_df.columns)\n",
    "fish_df['Species'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 분리 및 정규화\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X = fish_df.drop('Species', axis=1)\n",
    "y = fish_df['Species']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8067226890756303, 0.85)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 훈련 및 평가\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_clf = LogisticRegression()\n",
    "lr_clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "lr_clf.score(X_train_scaled, y_train), lr_clf.score(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Perch', 'Smelt', 'Pike', 'Perch', 'Perch'], dtype=object)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예측\n",
    "lr_clf.predict(X_test_scaled[:5])    # 2, 5, 3, 2, 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Bream', 'Parkki', 'Perch', 'Pike', 'Roach', 'Smelt', 'Whitefish'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델에 저장된 클래스 - 알파벳순\n",
    "# 차례대로 0, 1, 2, 3, 4, 5, 6\n",
    "lr_clf.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1.]\n",
      "[2 5 3 2 2]\n"
     ]
    }
   ],
   "source": [
    "y_pred_proba = lr_clf.predict_proba(X_test_scaled[:5])\n",
    "print(y_pred_proba.sum(axis=1))\n",
    "\n",
    "pred = np.argmax(y_pred_proba, axis=1)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.48182365e-01 -8.24525914e-02  6.40195780e-01  2.81982913e+00\n",
      "  -3.24265678e-01]\n",
      " [-3.35652274e-01 -8.21629219e-01 -8.35964486e-01  1.91914509e+00\n",
      "  -8.55835796e-01]\n",
      " [ 1.30718802e+00  3.21934486e-01 -1.31756955e+00 -1.71450422e+00\n",
      "   1.63944927e+00]\n",
      " [ 1.77729936e-03  1.72795327e+00  1.75781875e+00 -1.28734479e+00\n",
      "  -6.35651507e-01]\n",
      " [-8.13642475e-01 -5.25253484e-01  3.53652827e-01 -4.23614580e-01\n",
      "   6.28774619e-01]\n",
      " [-3.56471450e-01 -6.40955509e-01 -6.57339073e-01 -1.46487306e+00\n",
      "  -1.51637890e+00]\n",
      " [ 3.44983246e-01  2.04030481e-02  5.92057542e-02  1.51362439e-01\n",
      "   1.06390799e+00]] [ 0.38855598 -0.11529593  2.40847091  0.04967132  1.1590055  -3.78172256\n",
      " -0.10868521]\n",
      "(7, 5) (7,)\n"
     ]
    }
   ],
   "source": [
    "print(lr_clf.coef_, lr_clf.intercept_)\n",
    "print(lr_clf.coef_.shape, lr_clf.intercept_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.353342461290558\n",
      "0.7537803507202023\n",
      "2.5382602426869703\n",
      "-1.6725803505731105\n",
      "1.874043676938647\n",
      "0.35060605549425894\n",
      "-1.490767513976421\n",
      "Z: [[-2.35334246  0.75378035  2.53826024 -1.67258035  1.87404368  0.35060606\n",
      "  -1.49076751]]\n",
      "P: [[0.00409258 0.09149632 0.54499613 0.00808441 0.28049675 0.06113744\n",
      "  0.00969636]]\n",
      "label: ['Perch']\n"
     ]
    }
   ],
   "source": [
    "# 각 클래스별 z값 계산: 직접 계산 -> X_test_scaled[0]\n",
    "# w1x1 + w2x2 + w3x3 + w4x4 + w5x5 + b\n",
    "print(np.dot(lr_clf.coef_[0], X_test_scaled[0]) + lr_clf.intercept_[0])\n",
    "print(np.dot(lr_clf.coef_[1], X_test_scaled[0]) + lr_clf.intercept_[1])\n",
    "print(np.dot(lr_clf.coef_[2], X_test_scaled[0]) + lr_clf.intercept_[2])\n",
    "print(np.dot(lr_clf.coef_[3], X_test_scaled[0]) + lr_clf.intercept_[3])\n",
    "print(np.dot(lr_clf.coef_[4], X_test_scaled[0]) + lr_clf.intercept_[4])\n",
    "print(np.dot(lr_clf.coef_[5], X_test_scaled[0]) + lr_clf.intercept_[5])\n",
    "print(np.dot(lr_clf.coef_[6], X_test_scaled[0]) + lr_clf.intercept_[6])\n",
    "\n",
    "# 각 클래스별 z값 계산: 결정 함수\n",
    "Z = lr_clf.decision_function(X_test_scaled[:1])\n",
    "print(\"Z:\", Z)\n",
    "\n",
    "# softmax 함수 적용 -> 확률값 변환\n",
    "P = softmax(Z)\n",
    "print(\"P:\", P)\n",
    "\n",
    "# 확률값이 가장 높은 클래스로 예측\n",
    "label = lr_clf.classes_[np.argmax(P, axis=1)]\n",
    "print(\"label:\", label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pystudy_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
