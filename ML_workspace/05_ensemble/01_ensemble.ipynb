{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 앙상블 (Ensemble)\n",
    "- 다양한 모델을 결합하여 예측 성능을 향상시키는 방법\n",
    "- 투표(Voting), 배깅(Bagging), 부스팅(Boosting), 스태킹(Stacking) 네 가지로 구분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting\n",
    "- hard voting : 여러 개의 예측치에 대해 다수결로 결정\n",
    "- soft voting : 여러 개의 예측 확률을 평균내어 결정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 위스콘신 유방암 데이터셋 (Wisconsin Breast Cancer Dataset)\n",
    "\n",
    "유방암의 악성(Malignant)과 양성(Benign)을 분류하기 위해 자주 사용되는 데이터셋\n",
    "(의학적인 이미지를 바탕으로 유방암 종양의 특징을 수치화한 데이터)\n",
    "\n",
    "**데이터셋 개요**\n",
    "- **목적**: 유방암 종양이 악성(Malignant)인지, 양성(Benign)인지 분류\n",
    "- **샘플 수**: 569개\n",
    "- **특징(Features) 수**: 30개\n",
    "- **타겟(Target)**: 0(악성) 또는 1(양성)\n",
    "\n",
    "**데이터 구성**\n",
    "1. **Radius mean**: 종양의 평균 반지름\n",
    "2. **Texture mean**: 종양의 표면의 거칠기\n",
    "3. **Perimeter mean**: 종양의 평균 둘레 길이\n",
    "4. **Area mean**: 종양의 평균 면적\n",
    "5. **Smoothness mean**: 종양의 매끄러움 정도\n",
    "6. **Compactness mean**: 종양의 압축도\n",
    "7. **Concavity mean**: 종양의 오목함\n",
    "8. **Concave points mean**: 종양의 오목한 점 개수\n",
    "9. **Symmetry mean**: 종양의 대칭성\n",
    "10. **Fractal dimension mean**: 종양의 프랙탈 차원 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "data = load_breast_cancer()\n",
    "# print(data.DESCR)\n",
    "\n",
    "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "df['target'] = data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 준비 (분리)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### hard voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "knn_clf = KNeighborsClassifier()\n",
    "lr_clf = LogisticRegression()\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('knn_clf', knn_clf),\n",
    "        ('lr_clf', lr_clf),\n",
    "        ('dt_clf', dt_clf)\n",
    "    ],\n",
    "    voting='hard'    # 기본값\n",
    ")\n",
    "\n",
    "# 앙상블 모델 학습\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "# 예측 및 평가\n",
    "y_pred_train = voting_clf.predict(X_train)\n",
    "acc_score_train = accuracy_score(y_train, y_pred_train)\n",
    "print('학습 점수:', acc_score_train)\n",
    "\n",
    "y_pred_test = voting_clf.predict(X_test)\n",
    "acc_score_test = accuracy_score(y_test, y_pred_test)\n",
    "print('테스트 평가 점수:', acc_score_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hard voting 작동 원리 == 다수결\n",
    "start, end = 40, 50\n",
    "\n",
    "voting_clf_pred = voting_clf.predict(X_test[start:end])\n",
    "print('앙상블 예측값:', voting_clf_pred)\n",
    "\n",
    "for classfier in [knn_clf, lr_clf, dt_clf]:\n",
    "    # 개별 학습 및 예측\n",
    "    classfier.fit(X_train, y_train)\n",
    "    pred = classfier.predict(X_test)\n",
    "    acc_score = accuracy_score(y_test, pred)\n",
    "    \n",
    "    class_name = classfier.__class__.__name__    # 클래스의 이름 속성\n",
    "    print(f'{class_name} 개별 정확도: {acc_score:.4f}')\n",
    "    print(f'{class_name} 예측값: {pred[start:end]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### soft voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "knn_clf = KNeighborsClassifier()\n",
    "lr_clf = LogisticRegression()\n",
    "dt_clf = DecisionTreeClassifier(random_state=0)\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('knn_clf', knn_clf),\n",
    "        ('lr_clf', lr_clf),\n",
    "        ('dt_clf', dt_clf)\n",
    "    ],\n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "# 앙상블 모델 학습\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "# 예측 및 평가\n",
    "y_pred_train = voting_clf.predict(X_train)\n",
    "acc_score_train = accuracy_score(y_train, y_pred_train)\n",
    "print('학습 점수:', acc_score_train)\n",
    "\n",
    "y_pred_test = voting_clf.predict(X_test)\n",
    "acc_score_test = accuracy_score(y_test, y_pred_test)\n",
    "print('테스트 평가 점수:', acc_score_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# soft voting 작동 원리 == 각 예측기의 확률값 평균\n",
    "\n",
    "start, end = 40, 50\n",
    "\n",
    "voting_clf_pred_proba = voting_clf.predict_proba(X_test[start:end])\n",
    "print('앙상블 예측값:', voting_clf_pred_proba)\n",
    "\n",
    "averages = np.full_like(voting_clf_pred_proba, 0)\n",
    "\n",
    "for classfier in [knn_clf, lr_clf, dt_clf]:\n",
    "    # 개별 학습 및 예측\n",
    "    classfier.fit(X_train, y_train)\n",
    "    pred = classfier.predict(X_test)\n",
    "    acc_score = accuracy_score(y_test, pred)\n",
    "    pred_proba = classfier.predict_proba(X_test[start:end])\n",
    "\n",
    "    # 예측 확률 평균을 위한 합계\n",
    "    averages += pred_proba\n",
    "    \n",
    "    class_name = classfier.__class__.__name__    # 클래스의 이름 속성\n",
    "    # print(f'{class_name} 개별 정확도: {acc_score:.4f}')\n",
    "    # print(f'{class_name} 예측 확률: {pred_proba}')\n",
    "\n",
    "# 예측 확률 평균 계산 및 출력\n",
    "calc_averages = averages / 3\n",
    "print(\"각 모델별 예측값 평균:\", calc_averages)\n",
    "print(np.array_equal(voting_clf_pred_proba, calc_averages))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging\n",
    "- Bootstrap Aggregation\n",
    "- Bootstrap 방식의 샘플링: 각 estimator 마다 훈련 데이터를 뽑을 때, 중복 값을 허용하는 방식\n",
    "- 분류 모델의 경우, 각 tree(estimator)의 예측값을 다수결(hard voting) 결정\n",
    "- 회귀 모델의 경우, 각 tree(estimator)의 예측값을 평균내어 결정\n",
    "- 기본적으로 100개의 tree 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**하이퍼 파라미터**\n",
    "| **하이퍼파라미터**      | **설명**                                                                                     | **기본값**      |\n",
    "|--------------------------|--------------------------------------------------------------------------------------------|-----------------|\n",
    "| `n_estimators`           | 생성할 트리의 개수 지정 (트리의 개수가 많을수록 성능이 좋아질 수 있지만 계산 비용 증가) | 100             |\n",
    "| `criterion`              | 분할 품질을 측정하는 기준 (분류에서는 \"gini\" 또는 \"entropy\"를 사용)                 | \"gini\"          |\n",
    "| `max_depth`              | 각 트리의 최대 깊이 (설정하지 않으면 트리는 잎 노드가 순수해질 때까지 계속 확장) | None            |\n",
    "| `min_samples_split`      | 내부 노드를 분할하기 위해 필요한 최소 샘플 수 (과적합 방지 목적)                   | 2               |\n",
    "| `min_samples_leaf`       | 잎 노드가 되기 위해 필요한 최소 샘플 수 (과적합 방지 목적)                          | 1               |\n",
    "| `max_features`           | 각 트리를 분할할 때 고려할 최대 특성 수 ()\"auto\", \"sqrt\", \"log2\" 중 선택하거나, 특정 숫자 지정 가능) | \"auto\"          |\n",
    "| `bootstrap`              | 각 트리를 만들 때 부트스트랩 샘플링을 사용할지 여부를 결정                               | True            |\n",
    "| `random_state`           | 결과의 재현성을 위해 난수 시드 고정                                                  | None            |\n",
    "| `n_jobs`                 | 병렬 계산을 위해 사용할 CPU 코어 수를 지정 (-1로 설정하면 모든 코어를 사용)           | None            |\n",
    "| `class_weight`           | 각 클래스의 가중치를 자동으로 계산하거나 직접 지정 가능 (불균형 데이터 처리에 유용)    | None            |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, max_depth=7, random_state=0)\n",
    "\n",
    "# 학습\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "# 예측 및 평가\n",
    "y_pred_train = rf_clf.predict(X_train)\n",
    "acc_score_train = accuracy_score(y_train, y_pred_train)\n",
    "print('학습 점수:', acc_score_train)\n",
    "\n",
    "y_pred_test = rf_clf.predict(X_test)\n",
    "acc_score_test = accuracy_score(y_test, y_pred_test)\n",
    "print('테스트 평가 점수:', acc_score_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pystudy_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
