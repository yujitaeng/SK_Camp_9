{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightGBM\n",
    "\n",
    "**핵심 파라미터**\n",
    "<table border=\"1\">\n",
    "  <thead>\n",
    "    <tr>\n",
    "      <th>하이퍼파라미터</th>\n",
    "      <th>설명</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <td><b>num_leaves</b></td>\n",
    "      <td>한 트리에서 사용할 수 있는 리프의 최대 수를 지정한다. 모델의 복잡도를 결정하며, 값을 크게 하면 과적합(overfitting) 가능성이 높아진다.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td><b>max_depth</b></td>\n",
    "      <td>트리의 최대 깊이를 제한한다. <code>num_leaves</code>와 함께 과적합을 방지하기 위해 조정된다.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td><b>learning_rate</b></td>\n",
    "      <td>각 단계에서 트리의 기여도를 조정하는 학습률이다. 작은 값을 설정하면 모델 학습이 느리지만 성능이 더 좋을 수 있다.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td><b>n_estimators</b></td>\n",
    "      <td>생성할 트리의 수를 지정한다. 보통 <code>learning_rate</code>가 작을수록 큰 값을 설정한다.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td><b>min_data_in_leaf</b></td>\n",
    "      <td>리프 노드에서 최소 데이터 수를 제한하여 과적합을 방지한다.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td><b>feature_fraction</b></td>\n",
    "      <td>각 트리를 학습할 때 사용할 피처의 비율을 지정한다. 이 값을 줄이면 피처 샘플링 효과를 얻을 수 있다.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td><b>bagging_fraction & bagging_freq</b></td>\n",
    "      <td>데이터 샘플링을 통한 앙상블 효과를 얻기 위한 옵션으로, 일부 데이터만을 사용해 트리를 학습한다.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td><b>lambda_l1 & lambda_l2</b></td>\n",
    "      <td>L1 및 L2 정규화 항을 추가하여 모델의 가중치를 제한한다.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td><b>boosting</b></td>\n",
    "      <td>Boosting의 종류를 지정할 수 있다. 일반적으로 <code>gbdt</code>(Gradient Boosting Decision Tree)를 사용하지만, <code>dart</code>(Dropouts meet Multiple Additive Regression Trees)나 <code>goss</code>(Gradient-based One-Side Sampling)도 선택할 수 있다.</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = load_breast_cancer()\n",
    "\n",
    "# 학습-테스트 데이터 분리\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(data.data, data.target, random_state=0, test_size=0.2)\n",
    "\n",
    "# 학습데이터 -> 학습-검증 데이터 분리\n",
    "X_tr, X_val, y_tr, y_val = \\\n",
    "    train_test_split(X_train, y_train, random_state=0, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "lgbm = LGBMClassifier(\n",
    "    n_estimators=400,\n",
    "    learning_rate=0.7,\n",
    "    early_stopping_rounds=100,\n",
    "    verbose=1\n",
    ")\n",
    "eval_set = [(X_tr, y_tr), (X_val, y_val)]\n",
    "lgbm.fit(X_tr, y_tr, eval_set=eval_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm.score(X_train, y_train), lgbm.score(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pystudy_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
