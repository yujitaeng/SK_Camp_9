{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 자연어 처리 NLP | 텍스트 분석 Text Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 자연어 처리 : 사람이 사용하는 언어 전반에 대해서 이해하고, 처리하는 분야\n",
    "    - 음성인식, 번역, 감정분석, 요약, 질의응답, 언어생성 등 포괄적 분야  \n",
    "- 텍스트 분석 : 언어적 비정형 데이터에서 정보를 추출하고, 분석하는 작업 \n",
    "    - 텍스트 통계적분석, 주제분류, 텍스트 군집, 유사도분석 등   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 파이썬 텍스트분석 패키지 \n",
    "\n",
    "| **로고 이미지**                                                                                                 | **패키지**   | **설명**                                            | **주요 특징 및 기능**                                                   | **API 문서 URL**                                  |\n",
    "|------------------------------------------------------------------------------------------------------------|--------------|---------------------------------------------------|-----------------------------------------------------------------------|-------------------------------------------------|\n",
    "| ![nltk](https://images.javatpoint.com/tutorial/ai/images/natural-language-toolkit2.png)                   | **nltk**     | 가장 오래된 NLP 라이브러리 중 하나로, 다양한 자연어 처리 도구와 코퍼스 제공 | 토큰화, 품사 태깅, 어간 추출, 불용어 제거, 문법 구조 분석, 감정 분석 등에 유용 | [NLTK API Docs](https://www.nltk.org/api/nltk.html) |\n",
    "| ![gensim](https://radimrehurek.com/gensim/_static/images/gensim.png)                                       | **gensim**   | 주로 텍스트의 토픽 모델링과 문서 유사도 분석을 위한 라이브러리            | Word2Vec, FastText, LDA, 유사도 측정, 대용량 텍스트 처리에 최적화    | [Gensim API Docs](https://radimrehurek.com/gensim/) |\n",
    "| ![spacy](https://upload.wikimedia.org/wikipedia/commons/thumb/8/88/SpaCy_logo.svg/320px-SpaCy_logo.svg.png) | **spacy**    | 빠르고 효율적인 NLP 처리를 위해 개발된 라이브러리로, 산업용 프로젝트에 적합     | 빠른 토큰화, 품사 태깅, NER, 구문 분석, 벡터 표현 제공              | [SpaCy API Docs](https://spacy.io/api)             |\n",
    "| ![TextBlob](https://textblob.readthedocs.io/en/dev/_static/textblob-logo.png)                              | **TextBlob** | 간단한 NLP 작업을 위한 라이브러리로, 감정 분석과 텍스트 정제 등 지원  | 문법 교정, 감정 분석, 텍스트 번역 등과 같은 간단한 작업에 적합      | [TextBlob API Docs](https://textblob.readthedocs.io/en/dev/) |\n",
    "| ![KoNLPy](https://konlpy.org/en/latest/_static/konlpy.png)                                                 | **KoNLPy**   | 한국어 자연어 처리를 위한 라이브러리로, 여러 형태소 분석기를 제공          | Kkma, Hannanum, Komoran, Twitter, Mecab 형태소 분석기 지원            | [KoNLPy API Docs](https://konlpy.org/en/latest/)  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLTK (Natural Language Toolkit)\n",
    "- 파이썬에서 텍스트 처리 및 자연어 처리를 쉽게 다룰 수 있게 해주는 오픈 소스 라이브러리\n",
    "- NLTK는 다양한 언어 리소스와 알고리즘을 포함하고 있으며, 텍스트 마이닝, 텍스트 분석, 그리고 자연어 처리를 공부하거나 구현할 때 유용\n",
    "\n",
    "**주요 기능**\n",
    "1. **토큰화(Tokenization)**: 문장을 단어 또는 문장 단위로 나누는 작업\n",
    "    - 예를 들어, `\"I love NLP.\"`를 `['I', 'love', 'NLP', '.']`와 같이 나누는 기능을 제공한다.\n",
    "2. **품사 태깅(Part-of-Speech Tagging)**: 각 단어에 대해 해당 품사를 태깅하는 작업\n",
    "    - 예를 들어, `\"I love NLP.\"`에 대해 `[('I', 'PRP'), ('love', 'VBP'), ('NLP', 'NNP'), ('.', '.')]`와 같이 태깅한다.\n",
    "3. **명사구 추출(Chunking)**: 문장에서 명사구와 같은 특정 구문을 추출하는 작업\n",
    "4. **어근 추출(Lemmatization) 및 어간 추출(Stemming)**: 단어의 기본 형태를 찾는 작업으로, 동사의 기본형을 찾거나 복수형을 단수형으로 변환하는 등의 작업 수행\n",
    "5. **텍스트 분류(Classification)**: Naive Bayes, MaxEnt 등의 분류 모델을 사용해 텍스트 분류 가능\n",
    "6. **코퍼스(corpus) 제공**: 영화 리뷰, 뉴스 기사 등 여러 텍스트 데이터셋을 포함하고 있어 학습과 실습에 유용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda install nltk -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Playdata\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Playdata\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Playdata\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.__version__\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NLTK',\n",
       " 'is',\n",
       " 'a',\n",
       " 'powerful',\n",
       " 'library',\n",
       " 'for',\n",
       " 'NLP',\n",
       " '!',\n",
       " '!',\n",
       " '!',\n",
       " '!',\n",
       " '!']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "\n",
    "text = 'NLTK is a powerful library for NLP!!!!!'\n",
    "word_tokenize(text)    # 단어 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The Matrix is everywhere its all around us, here even in this room.',\n",
       " 'You can see it out your window or on your television.',\n",
       " 'You feel it when you go to work, or go to church or pay your taxes.']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = '''The Matrix is everywhere its all around us, here even in this room.\n",
    "You can see it out your window or on your television.\n",
    "You feel it when you go to work, or go to church or pay your taxes.'''\n",
    "\n",
    "sent_tokenize(text)    # 문장 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 15 12 18\n"
     ]
    }
   ],
   "source": [
    "# 문장별 단어 토큰화\n",
    "def tokenize_text(text):\n",
    "    sentences = sent_tokenize(text)\n",
    "    return [word_tokenize(sentence) for sentence in sentences]\n",
    "\n",
    "result = tokenize_text(text)\n",
    "print(len(result), len(result[0]), len(result[1]), len(result[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('The', 'Matrix'), ('Matrix', 'is'), ('is', 'everywhere'), ('everywhere', 'its'), ('its', 'all'), ('all', 'around'), ('around', 'us'), ('us', ','), (',', 'here'), ('here', 'even'), ('even', 'in'), ('in', 'this'), ('this', 'room'), ('room', '.')]\n",
      "[('The', 'Matrix', 'is'), ('Matrix', 'is', 'everywhere'), ('is', 'everywhere', 'its'), ('everywhere', 'its', 'all'), ('its', 'all', 'around'), ('all', 'around', 'us'), ('around', 'us', ','), ('us', ',', 'here'), (',', 'here', 'even'), ('here', 'even', 'in'), ('even', 'in', 'this'), ('in', 'this', 'room'), ('this', 'room', '.')]\n"
     ]
    }
   ],
   "source": [
    "# n-gram\n",
    "from nltk import ngrams\n",
    "\n",
    "text = 'The Matrix is everywhere its all around us, here even in this room.'\n",
    "tokens = word_tokenize(text)\n",
    "\n",
    "bigram = ngrams(tokens, 2)\n",
    "print([token for token in bigram])\n",
    "\n",
    "trigram = ngrams(tokens, 3)\n",
    "print([token for token in trigram])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 불용어(stopwords) 제거\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# stopwords.fileids()\n",
    "\n",
    "print(len(stopwords.words('english')))\n",
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['matrix', 'everywhere', 'around', 'us', ',', 'even', 'room', '.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'The Matrix is everywhere its all around us, here even in this room.'\n",
    "stopwords_list = stopwords.words('english')\n",
    "\n",
    "tokens = []\n",
    "for word in word_tokenize(text):    # 토큰화\n",
    "    word = word.lower()    # 소문자 변환\n",
    "    if word not in stopwords_list:    # 불용어 처리\n",
    "        tokens.append(word)\n",
    "\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 특성 벡터화 Feature Vectorization\n",
    "1. BOW(Bag of Words): 문서가 가지는 모든 단어를 문맥이나 순서를 무시하고 일괄적으로 단어에 대해 빈도 값을 부여해 피처 값을 추출하는 모델이다.\n",
    "    \n",
    "   <img src=\"https://miro.medium.com/v2/resize:fit:1400/1*S8uW62e3AbYw3gnylm4eDg.png\" width=\"500px\">\n",
    "\n",
    "2. Word Embedding: 단어를 밀집 벡터(dense vector)로 표현하는 방법으로, 단어의 의미와 관계를 보존하며 벡터로 표현한다.\n",
    "    \n",
    "    <img src=\"https://miro.medium.com/v2/resize:fit:1400/1*jpnKO5X0Ii8PVdQYFO2z1Q.png\" width=\"500px\">\n",
    "\n",
    "\n",
    "| **구분**             | **Bag-of-Words (BOW)**                             | **Word Embedding**                             |\n",
    "|----------------------|--------------------------------------------------|------------------------------------------------|\n",
    "| **개념**             | 문서를 단어의 출현 빈도로 표현                   | 단어를 실수 벡터로 표현                       |\n",
    "| **특징**             | - 단어의 순서와 의미를 고려하지 않음             | - 단어 간 의미적 유사성을 반영                |\n",
    "|                      | - 고차원, 희소 벡터 생성                         | - 밀집된 저차원 벡터 생성                     |\n",
    "| **대표 방법**        | Count Vector, TF-IDF                             | Word2Vec, GloVe, FastText                     |\n",
    "| **장점**             | - 구현이 간단하고 이해하기 쉬움                  | - 문맥 정보 반영 가능                         |\n",
    "|                      | - 단순 텍스트 데이터 분석에 유용                 | - 유사한 단어를 벡터 공간 상에서 가깝게 위치 |\n",
    "| **단점**             | - 의미적 관계와 단어의 순서 정보 없음            | - 많은 데이터와 학습 시간 필요                |\n",
    "|                      | - 고차원 희소 벡터 문제                          | - 구현이 상대적으로 복잡                      |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### BOW - CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Compressed Sparse Row sparse matrix of dtype 'int64'\n",
      "\twith 56 stored elements and shape (2, 51)>\n",
      "  Coords\tValues\n",
      "  (0, 0)\t1\n",
      "  (0, 2)\t1\n",
      "  (0, 6)\t1\n",
      "  (0, 7)\t1\n",
      "  (0, 10)\t1\n",
      "  (0, 11)\t1\n",
      "  (0, 12)\t1\n",
      "  (0, 13)\t2\n",
      "  (0, 15)\t1\n",
      "  (0, 18)\t1\n",
      "  (0, 19)\t1\n",
      "  (0, 20)\t2\n",
      "  (0, 21)\t1\n",
      "  (0, 22)\t1\n",
      "  (0, 23)\t1\n",
      "  (0, 24)\t3\n",
      "  (0, 25)\t1\n",
      "  (0, 26)\t1\n",
      "  (0, 30)\t1\n",
      "  (0, 31)\t1\n",
      "  (0, 36)\t1\n",
      "  (0, 37)\t1\n",
      "  (0, 38)\t1\n",
      "  (0, 39)\t1\n",
      "  (0, 40)\t2\n",
      "  :\t:\n",
      "  (1, 1)\t4\n",
      "  (1, 3)\t1\n",
      "  (1, 4)\t2\n",
      "  (1, 5)\t1\n",
      "  (1, 8)\t1\n",
      "  (1, 9)\t1\n",
      "  (1, 14)\t1\n",
      "  (1, 16)\t1\n",
      "  (1, 17)\t1\n",
      "  (1, 18)\t2\n",
      "  (1, 27)\t2\n",
      "  (1, 28)\t1\n",
      "  (1, 29)\t1\n",
      "  (1, 32)\t1\n",
      "  (1, 33)\t1\n",
      "  (1, 34)\t1\n",
      "  (1, 35)\t2\n",
      "  (1, 38)\t4\n",
      "  (1, 40)\t1\n",
      "  (1, 42)\t1\n",
      "  (1, 43)\t1\n",
      "  (1, 44)\t1\n",
      "  (1, 47)\t1\n",
      "  (1, 49)\t7\n",
      "  (1, 50)\t1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "text1 = 'The Matrix is everywhere its all around us, here even in this room. \\\n",
    "You can see it out your window or on your television. \\\n",
    "You feel it when you go to work, or go to church or pay your taxes.'\n",
    "\n",
    "text2 = 'You take the blue pill and the story ends.  You wake in your bed and you believe whatever you want to believe \\\n",
    "You take the red pill and you stay in Wonderland and I show you how deep the rabbit-hole goes.'\n",
    "\n",
    "texts = [text1, text2]\n",
    "\n",
    "count_vectorizer = CountVectorizer()\n",
    "count_vectorizer.fit(texts)\n",
    "text_vecs = count_vectorizer.transform(texts)\n",
    "\n",
    "print(text_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['all' 'and' 'around' 'bed' 'believe' 'blue' 'can' 'church' 'deep' 'ends'\n",
      " 'even' 'everywhere' 'feel' 'go' 'goes' 'here' 'hole' 'how' 'in' 'is' 'it'\n",
      " 'its' 'matrix' 'on' 'or' 'out' 'pay' 'pill' 'rabbit' 'red' 'room' 'see'\n",
      " 'show' 'stay' 'story' 'take' 'taxes' 'television' 'the' 'this' 'to' 'us'\n",
      " 'wake' 'want' 'whatever' 'when' 'window' 'wonderland' 'work' 'you' 'your']\n",
      "{'the': 38, 'matrix': 22, 'is': 19, 'everywhere': 11, 'its': 21, 'all': 0, 'around': 2, 'us': 41, 'here': 15, 'even': 10, 'in': 18, 'this': 39, 'room': 30, 'you': 49, 'can': 6, 'see': 31, 'it': 20, 'out': 25, 'your': 50, 'window': 46, 'or': 24, 'on': 23, 'television': 37, 'feel': 12, 'when': 45, 'go': 13, 'to': 40, 'work': 48, 'church': 7, 'pay': 26, 'taxes': 36, 'take': 35, 'blue': 5, 'pill': 27, 'and': 1, 'story': 34, 'ends': 9, 'wake': 42, 'bed': 3, 'believe': 4, 'whatever': 44, 'want': 43, 'red': 29, 'stay': 33, 'wonderland': 47, 'show': 32, 'how': 17, 'deep': 8, 'rabbit': 28, 'hole': 16, 'goes': 14}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>all</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>and</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>around</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bed</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>believe</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>blue</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>can</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>church</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>deep</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ends</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>even</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>everywhere</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>feel</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>go</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>goes</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>here</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>hole</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>how</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>in</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>is</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>it</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>its</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>matrix</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>on</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>or</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>out</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>pay</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>pill</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>rabbit</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>red</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>room</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>see</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>show</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>stay</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>story</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>take</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>taxes</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>television</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>the</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>this</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>to</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>us</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>wake</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>want</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>whatever</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>when</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>window</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>wonderland</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>work</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>you</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>your</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          word  idx\n",
       "0          all    0\n",
       "1          and    1\n",
       "2       around    2\n",
       "3          bed    3\n",
       "4      believe    4\n",
       "5         blue    5\n",
       "6          can    6\n",
       "7       church    7\n",
       "8         deep    8\n",
       "9         ends    9\n",
       "10        even   10\n",
       "11  everywhere   11\n",
       "12        feel   12\n",
       "13          go   13\n",
       "14        goes   14\n",
       "15        here   15\n",
       "16        hole   16\n",
       "17         how   17\n",
       "18          in   18\n",
       "19          is   19\n",
       "20          it   20\n",
       "21         its   21\n",
       "22      matrix   22\n",
       "23          on   23\n",
       "24          or   24\n",
       "25         out   25\n",
       "26         pay   26\n",
       "27        pill   27\n",
       "28      rabbit   28\n",
       "29         red   29\n",
       "30        room   30\n",
       "31         see   31\n",
       "32        show   32\n",
       "33        stay   33\n",
       "34       story   34\n",
       "35        take   35\n",
       "36       taxes   36\n",
       "37  television   37\n",
       "38         the   38\n",
       "39        this   39\n",
       "40          to   40\n",
       "41          us   41\n",
       "42        wake   42\n",
       "43        want   43\n",
       "44    whatever   44\n",
       "45        when   45\n",
       "46      window   46\n",
       "47  wonderland   47\n",
       "48        work   48\n",
       "49         you   49\n",
       "50        your   50"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "print(count_vectorizer.get_feature_names_out())\n",
    "print(count_vectorizer.vocabulary_)\n",
    "\n",
    "vocab = sorted(count_vectorizer.vocabulary_.items(), key=lambda x:x[1])\n",
    "vocab_df = pd.DataFrame(vocab, columns=['word', 'idx'])\n",
    "vocab_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>all</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>and</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>around</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bed</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>believe</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>blue</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>can</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>church</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>deep</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ends</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>even</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>everywhere</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>feel</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>go</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>goes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>here</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>hole</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>how</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>in</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>is</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>it</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>its</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>matrix</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>on</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>or</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>out</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>pay</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>pill</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>rabbit</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>red</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>room</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>see</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>show</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>stay</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>story</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>take</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>taxes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>television</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>the</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>this</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>to</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>us</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>wake</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>want</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>whatever</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>when</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>window</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>wonderland</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>work</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>you</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>your</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          word  count\n",
       "0          all      1\n",
       "1          and      4\n",
       "2       around      1\n",
       "3          bed      1\n",
       "4      believe      2\n",
       "5         blue      1\n",
       "6          can      1\n",
       "7       church      1\n",
       "8         deep      1\n",
       "9         ends      1\n",
       "10        even      1\n",
       "11  everywhere      1\n",
       "12        feel      1\n",
       "13          go      2\n",
       "14        goes      1\n",
       "15        here      1\n",
       "16        hole      1\n",
       "17         how      1\n",
       "18          in      3\n",
       "19          is      1\n",
       "20          it      2\n",
       "21         its      1\n",
       "22      matrix      1\n",
       "23          on      1\n",
       "24          or      3\n",
       "25         out      1\n",
       "26         pay      1\n",
       "27        pill      2\n",
       "28      rabbit      1\n",
       "29         red      1\n",
       "30        room      1\n",
       "31         see      1\n",
       "32        show      1\n",
       "33        stay      1\n",
       "34       story      1\n",
       "35        take      2\n",
       "36       taxes      1\n",
       "37  television      1\n",
       "38         the      5\n",
       "39        this      1\n",
       "40          to      3\n",
       "41          us      1\n",
       "42        wake      1\n",
       "43        want      1\n",
       "44    whatever      1\n",
       "45        when      1\n",
       "46      window      1\n",
       "47  wonderland      1\n",
       "48        work      1\n",
       "49         you     10\n",
       "50        your      4"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 단어별 등장 횟수 구하기\n",
    "word_counts = text_vecs.toarray().sum(axis=0)\n",
    "\n",
    "# 단어 데이터프레임에 빈도 추가\n",
    "vocab_df['count'] = vocab_df['idx'].apply(lambda i: word_counts[i])\n",
    "\n",
    "# idx 열 제거 (불필요함)\n",
    "vocab_df = vocab_df.drop(columns=['idx'])\n",
    "\n",
    "vocab_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 24)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bed</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>believe</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blue</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>church</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>deep</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ends</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>feel</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>goes</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>hole</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>matrix</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>pay</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>pill</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>rabbit</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>red</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>room</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>stay</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>story</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>taxes</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>television</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>wake</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>want</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>window</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>wonderland</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>work</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          word  idx\n",
       "0          bed    0\n",
       "1      believe    1\n",
       "2         blue    2\n",
       "3       church    3\n",
       "4         deep    4\n",
       "5         ends    5\n",
       "6         feel    6\n",
       "7         goes    7\n",
       "8         hole    8\n",
       "9       matrix    9\n",
       "10         pay   10\n",
       "11        pill   11\n",
       "12      rabbit   12\n",
       "13         red   13\n",
       "14        room   14\n",
       "15        stay   15\n",
       "16       story   16\n",
       "17       taxes   17\n",
       "18  television   18\n",
       "19        wake   19\n",
       "20        want   20\n",
       "21      window   21\n",
       "22  wonderland   22\n",
       "23        work   23"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CountVectorizer(stop_words='언어') : 불용어 제거\n",
    "count_vectorizer = CountVectorizer(stop_words='english')\n",
    "texts_vecs = count_vectorizer.fit_transform(texts)\n",
    "print(texts_vecs.toarray().shape)\n",
    "\n",
    "vocab = sorted(count_vectorizer.vocabulary_.items(), key=lambda x:x[1])\n",
    "vocab_df = pd.DataFrame(vocab, columns=['word', 'idx'])\n",
    "vocab_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 20)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['bed', 'believe', 'pill', 'rabbit hole', 'red', 'red pill', 'room',\n",
       "       'room window', 'stay', 'stay wonderland', 'story', 'story ends',\n",
       "       'television', 'television feel', 'wake', 'wake bed', 'want',\n",
       "       'want believe', 'window', 'window television'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer = CountVectorizer(\n",
    "    stop_words='english',\n",
    "    ngram_range=(1, 2),    # n-gram 범위 지정 (최소값, 최대값) / 기본값 (1, 1)\n",
    "    max_features=20    # 빈도수 상위인 n개의 데이터 사용\n",
    ")\n",
    "texts_vecs = count_vectorizer.fit_transform(texts)\n",
    "print(texts_vecs.toarray().shape)\n",
    "\n",
    "count_vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### BOW - TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- TF-IDF == Term Frequency-Inverse Document Frequency\n",
    "\n",
    "**용어** \n",
    "- $tf(t, d)$: 특정 단어 $t$가 문서 $d$에서 등장한 횟수 (Term Frequency)\n",
    "- $df(t)$: 특정 단어 $t$가 등장한 문서의 수 (Document Frequency)\n",
    "- $N$: 전체 문서의 수\n",
    "\n",
    "**TF (Term Frequency)**\n",
    "- 단어 $t$의 문서 $d$에서의 빈도를 계산하는데, 가장 일반적인 방법은 해당 단어의 단순 빈도로 정의한다.\n",
    "\n",
    "$\n",
    "tf(t, d) = \\frac{\\text{단어 } t \\text{의 문서 } d \\text{ 내 등장 횟수}}{\\text{문서 } d \\text{의 전체 단어 수}}\n",
    "$\n",
    "\n",
    "**IDF (Inverse Document Frequency)**\n",
    "- 단어가 전체 문서에서 얼마나 중요한지를 계산한다.\n",
    "- 특정 단어가 많은 문서에서 등장하면, 이 단어는 중요도가 낮아진다. 이를 반영하기 위해 아래와 같은 식을 사용한다.\n",
    "\n",
    "$\n",
    "idf(t) = \\log\\left(\\frac{N}{1 + df(t)}\\right)\n",
    "$\n",
    "\n",
    "- 여기서 $1$을 더하는 이유는, 특정 단어가 모든 문서에 등장하지 않을 경우 $df(t) = 0$이 되어, 분모가 $0$이 되는 것을 방지하기 위함이다.\n",
    "  - 예를 들어, $\\log(5/(1+1))$과 $\\log(5/(1+2))$를 계산하면, 각각 $0.3979$와 $0.2218$이 된다.\n",
    "\n",
    "**TF-IDF 계산**\n",
    "- 위의 TF와 IDF를 결합하여 TF-IDF 가중치를 계산한다.\n",
    "\n",
    "$\n",
    "\\text{tf-idf}(t, d) = tf(t, d) \\times idf(t)\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TfidfVectorizer의 주요 파라미터**\n",
    "<table border=\"1\" cellpadding=\"5\" cellspacing=\"0\">\n",
    "  <tr style=\"background-color: #f2f2f2;\">\n",
    "    <th>Parameter</th>\n",
    "    <th>Description</th>\n",
    "    <th>Default Value</th>\n",
    "  </tr>\n",
    "  <tr style=\"background-color: #ffeb99;\">\n",
    "    <td><b>max_df</b></td>\n",
    "    <td>문서의 비율 값으로서, 해당 비율 이상 나타나는 단어를 무시한다. <br> 예를 들어, max_df=0.8이면, 80% 이상의 문서에서 나타나는 단어는 제외된다.</td>\n",
    "    <td>1.0</td>\n",
    "  </tr>\n",
    "  <tr style=\"background-color: #ffeb99;\">\n",
    "    <td><b>min_df</b></td>\n",
    "    <td>문서의 비율 값 또는 정수로, 해당 비율 이하 나타나는 단어를 무시한다. <br> 예를 들어, min_df=2이면, 두 개 이하의 문서에서만 나타나는 단어는 제외된다.</td>\n",
    "    <td>1</td>\n",
    "  </tr>\n",
    "  <tr style=\"background-color: #ffeb99;\">\n",
    "    <td><b>ngram_range</b></td>\n",
    "    <td>(min_n, max_n) 형식으로, 사용할 n-gram의 범위를 정의한다. <br> 예를 들어, (1, 2)로 설정하면 unigram과 bigram을 고려한다.</td>\n",
    "    <td>(1, 1)</td>\n",
    "  </tr>\n",
    "  <tr style=\"background-color: #ffeb99;\">\n",
    "    <td>stop_words</td>\n",
    "    <td>불용어를 지정할 수 있다. \"english\"로 설정하면 영어 불용어를 사용한다.</td>\n",
    "    <td>None</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>max_features</td>\n",
    "    <td>벡터화할 때 고려할 최대 단어 수를 설정한다. 빈도순으로 상위 단어들이 선택된다.</td>\n",
    "    <td>None</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>use_idf</td>\n",
    "    <td>IDF(역문서 빈도)를 사용할지 여부를 지정한다. False로 설정하면 단순히 TF 값만 사용한다.</td>\n",
    "    <td>True</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>smooth_idf</td>\n",
    "    <td>IDF 계산 시, 0으로 나누는 것을 피하기 위해 추가적인 smoothing을 수행한다.</td>\n",
    "    <td>True</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>sublinear_tf</td>\n",
    "    <td>TF 값에 대해 sublinear scaling (1 + log(tf))를 적용할지 지정한다.</td>\n",
    "    <td>False</td>\n",
    "  </tr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.33333333, 0.        ,\n",
       "        0.        , 0.33333333, 0.        , 0.        , 0.33333333,\n",
       "        0.33333333, 0.        , 0.        , 0.        , 0.33333333,\n",
       "        0.        , 0.        , 0.33333333, 0.33333333, 0.        ,\n",
       "        0.        , 0.33333333, 0.        , 0.33333333],\n",
       "       [0.21821789, 0.43643578, 0.21821789, 0.        , 0.21821789,\n",
       "        0.21821789, 0.        , 0.21821789, 0.21821789, 0.        ,\n",
       "        0.        , 0.43643578, 0.21821789, 0.21821789, 0.        ,\n",
       "        0.21821789, 0.21821789, 0.        , 0.        , 0.21821789,\n",
       "        0.21821789, 0.        , 0.21821789, 0.        ]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array(['bed', 'believe', 'blue', 'church', 'deep', 'ends', 'feel', 'goes',\n",
       "       'hole', 'matrix', 'pay', 'pill', 'rabbit', 'red', 'room', 'stay',\n",
       "       'story', 'taxes', 'television', 'wake', 'want', 'window',\n",
       "       'wonderland', 'work'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "texts_vecs = tfidf_vectorizer.fit_transform(texts)\n",
    "\n",
    "display(texts_vecs.toarray())\n",
    "tfidf_vectorizer.get_feature_names_out()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pystudy_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
