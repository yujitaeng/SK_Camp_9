{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# n-gram 언어 모델링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({('.', '오늘은'): 4, ('오늘은', '날씨가'): 2, ('좋다', '.'): 2, ('많다', '.'): 2, ('날씨가', '좋다'): 1, ('오늘은', '기분이'): 1, ('기분이', '좋다'): 1, ('오늘은', '일이'): 1, ('일이', '많다'): 1, ('오늘은', '사람이'): 1, ('사람이', '많다'): 1, ('날씨가', '맑다'): 1, ('맑다', '.'): 1})\n",
      "P(날씨가|오늘은) = 0.400\n",
      "P(좋다|날씨가) = 0.500\n",
      "P(.|좋다) = 1.000\n",
      "P(오늘은|.) = 0.800\n",
      "P(기분이|오늘은) = 0.200\n",
      "P(좋다|기분이) = 1.000\n",
      "P(일이|오늘은) = 0.200\n",
      "P(많다|일이) = 1.000\n",
      "P(.|많다) = 1.000\n",
      "P(사람이|오늘은) = 0.200\n",
      "P(많다|사람이) = 1.000\n",
      "P(맑다|날씨가) = 0.500\n",
      "P(.|맑다) = 1.000\n"
     ]
    }
   ],
   "source": [
    "text = \"오늘은 날씨가 좋다. 오늘은 기분이 좋다. 오늘은 일이 많다. 오늘은 사람이 많다. 오늘은 날씨가 맑다.\"\n",
    "\n",
    "tokens = nltk.word_tokenize(text)\n",
    "\n",
    "# 1-gram, 2-gram 생성 -> 빈도수 계산\n",
    "unigrams = tokens\n",
    "bigrams = list(ngrams(tokens, 2))\n",
    "\n",
    "unigram_freq = Counter(unigrams)\n",
    "bigrams_freq = Counter(bigrams)\n",
    "print(bigrams_freq)\n",
    "\n",
    "# 조건부 확률 계산\n",
    "for (w1, w2), freq in bigrams_freq.items():\n",
    "    prob = freq / unigram_freq[w1]\n",
    "    print(f'P({w2}|{w1}) = {prob:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perplexity 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def compute_bigram_perplexity(test_text, unigram_freq, bigram_freq):\n",
    "    test_tokens = nltk.word_tokenize(test_text)\n",
    "    test_bigrams = list(ngrams(test_tokens, 2))\n",
    "\n",
    "    log_prob_sum = 0\n",
    "    N = len(test_bigrams)\n",
    "\n",
    "    for bigram in test_bigrams:\n",
    "        w1, w2 = bigram\n",
    "        prob = bigram_freq.get(bigram, 0) / unigram_freq.get(w1, 1)\n",
    "        if prob == 0:\n",
    "            prob = 1e-10\n",
    "        log_prob_sum += math.log2(prob)\n",
    "\n",
    "    cross_entropy = -log_prob_sum / N\n",
    "    perplexity = math.pow(2, cross_entropy)\n",
    "    return perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = \"자연어 처리는 재미있다. 자연어 처리는 어렵지만 도전하고 싶다. 오늘은 날씨가 좋다.\"\n",
    "train_tokens = nltk.word_tokenize(train_text)\n",
    "unigrams = train_tokens\n",
    "bigrams = list(ngrams(train_tokens, 2))\n",
    "unigram_freq = Counter(unigrams)\n",
    "bigram_freq = Counter(bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장: 자연어 처리는 재미있다. | perplexity: 1.2599\n",
      "문장: 자연어 처리는 어렵지만 도전하고 싶다. | perplexity: 1.1487\n",
      "문장: 오늘은 날씨가 좋다. | perplexity: 1.0000\n",
      "문장: 기계 번역은 어렵다. | perplexity: 10000000000.0000\n",
      "문장: 자연어 처리에 도전하고 싶다. | perplexity: 100000.0000\n",
      "문장: 오늘 날씨가 흐리다 | perplexity: 10000000000.0000\n"
     ]
    }
   ],
   "source": [
    "test_sentences = [\n",
    "    \"자연어 처리는 재미있다.\",\n",
    "    \"자연어 처리는 어렵지만 도전하고 싶다.\",\n",
    "    \"오늘은 날씨가 좋다.\",\n",
    "    \"기계 번역은 어렵다.\",\n",
    "    \"자연어 처리에 도전하고 싶다.\",\n",
    "    \"오늘 날씨가 흐리다\"\n",
    "]\n",
    "\n",
    "for sentence in test_sentences:\n",
    "    pp = compute_bigram_perplexity(sentence, unigram_freq, bigram_freq)\n",
    "    print(f'문장: {sentence} | perplexity: {pp:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pystudy_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
