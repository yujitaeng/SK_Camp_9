{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seq2Seq Q&A Chatbot 구현 실습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 취득"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12시 땡!</td>\n",
       "      <td>하루가 또 가네요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3박4일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3박4일 정도 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPL 심하네</td>\n",
       "      <td>눈살이 찌푸려지죠.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11818</th>\n",
       "      <td>훔쳐보는 것도 눈치 보임.</td>\n",
       "      <td>티가 나니까 눈치가 보이는 거죠!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11819</th>\n",
       "      <td>훔쳐보는 것도 눈치 보임.</td>\n",
       "      <td>훔쳐보는 거 티나나봐요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11820</th>\n",
       "      <td>흑기사 해주는 짝남.</td>\n",
       "      <td>설렜겠어요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11821</th>\n",
       "      <td>힘든 연애 좋은 연애라는게 무슨 차이일까?</td>\n",
       "      <td>잘 헤어질 수 있는 사이 여부인 거 같아요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11822</th>\n",
       "      <td>힘들어서 결혼할까봐</td>\n",
       "      <td>도피성 결혼은 하지 않길 바라요.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11823 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Q                         A\n",
       "0                       12시 땡!                하루가 또 가네요.\n",
       "1                  1지망 학교 떨어졌어                 위로해 드립니다.\n",
       "2                 3박4일 놀러가고 싶다               여행은 언제나 좋죠.\n",
       "3              3박4일 정도 놀러가고 싶다               여행은 언제나 좋죠.\n",
       "4                      PPL 심하네                눈살이 찌푸려지죠.\n",
       "...                        ...                       ...\n",
       "11818           훔쳐보는 것도 눈치 보임.        티가 나니까 눈치가 보이는 거죠!\n",
       "11819           훔쳐보는 것도 눈치 보임.             훔쳐보는 거 티나나봐요.\n",
       "11820              흑기사 해주는 짝남.                    설렜겠어요.\n",
       "11821  힘든 연애 좋은 연애라는게 무슨 차이일까?  잘 헤어질 수 있는 사이 여부인 거 같아요.\n",
       "11822               힘들어서 결혼할까봐        도피성 결혼은 하지 않길 바라요.\n",
       "\n",
       "[11823 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/songys/Chatbot_data/refs/heads/master/ChatbotData.csv')\n",
    "df = df[['Q', 'A']]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r\"[ ]+\", \" \", text)\n",
    "    text = text.strip()\n",
    "    return text\n",
    "\n",
    "# 질문과 답변에 전처리 적용 \n",
    "df['Q'] = df['Q'].apply(preprocess_text)\n",
    "df['A'] = df['A'].apply(preprocess_text)\n",
    "\n",
    "# 학습용 텍스트 파일 생성 (Q + A)\n",
    "with open('chatbot_train_data.txt', 'w', encoding='utf-8') as f:\n",
    "    for q, a in zip(df['Q'], df['A']):\n",
    "        f.write(q + '\\t' + a + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 토커나이저 학습 (sentencepiece 활용)\n",
    "- 접두사, 접미사 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sentencepiece as spm\n",
    "\n",
    "# Sentencepiece 모델 학습\n",
    "spm.SentencePieceTrainer.Train(\n",
    "    '--input=chatbot_train_data.txt --model_prefix=chatbot_model --vocab_size=2000'\n",
    ")\n",
    "\n",
    "# 학습된 토크나이저 로드\n",
    "sp = spm.SentencePieceProcessor()\n",
    "sp.Load('chatbot_model.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 학습용 데이터 Q_input, A_input, A_target 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_input = [sp.EncodeAsIds(q) for q in df['Q']]\n",
    "A_input = [sp.EncodeAsIds(a) for a in df['A']]\n",
    "A_target = [ids + [sp.piece_to_id('</s')] for ids in A_input]  # 디코더 종료 토큰 추가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼파라미터 설정\n",
    "VOCAB_SIZE = 5000\n",
    "EMBEDDING_DIM = 256\n",
    "HIDDEN_UNITS = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 인코더 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_encoder():\n",
    "    inputs = tf.keras.Input(shape=(None, ), dtype='int32')\n",
    "    embedding = layers.Embedding(VOCAB_SIZE, EMBEDDING_DIM)(inputs)\n",
    "    outputs, h, c = layers.LSTM(HIDDEN_UNITS, return_state=True)(embedding)\n",
    "    return tf.keras.Model(inputs, [outputs, h, c])\n",
    "\n",
    "encoder = build_encoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 디코더 (teacher-forcing 모델) 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_decoder():\n",
    "    inputs = tf.keras.Input(shape=(None, ), dtype='int32')\n",
    "    encoder_outputs = tf.keras.Input(shape=(HIDDEN_UNITS, ))\n",
    "    encoder_h = tf.keras.Input(shape=(HIDDEN_UNITS, ))\n",
    "    encoder_c = tf.keras.Input(shape=(HIDDEN_UNITS, ))\n",
    "\n",
    "    embedding = layers.Embedding(VOCAB_SIZE, EMBEDDING_DIM)(inputs)\n",
    "    lstm = layers.LSTM(HIDDEN_UNITS, return_sequences=True, return_state=True)\n",
    "    outputs, _, _ = lstm(embedding, initial_state=[encoder_h, encoder_c])\n",
    "    outputs = layers.Dense(VOCAB_SIZE, activation='softmax')(outputs)\n",
    "\n",
    "    return tf.keras.Model([inputs, encoder_outputs, encoder_h, encoder_c], outputs)\n",
    "\n",
    "decoder = build_decoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 학습 준비\n",
    "class Seq2Seq(tf.keras.Model):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def call(self, inputs):\n",
    "        encoder_inputs, decoder_inputs = inputs\n",
    "\n",
    "        encoder_outputs, h, c = self.encoder(encoder_inputs)\n",
    "        decoder_outputs = self.decoder([decoder_inputs, encoder_outputs, h, c])\n",
    "\n",
    "        return decoder_outputs\n",
    "    \n",
    "model = Seq2Seq(encoder, decoder)\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "max_len = 50\n",
    "\n",
    "Q_input = pad_sequences(Q_input, maxlen=max_len, padding='post')\n",
    "A_input = pad_sequences(A_input, maxlen=max_len, padding='post')\n",
    "A_target = pad_sequences(A_target, maxlen=max_len, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 524ms/step - accuracy: 0.8100 - loss: 1.9369\n",
      "Epoch 2/20\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 534ms/step - accuracy: 0.8720 - loss: 0.7957\n",
      "Epoch 3/20\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 532ms/step - accuracy: 0.9123 - loss: 0.5402\n",
      "Epoch 4/20\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 531ms/step - accuracy: 0.9478 - loss: 0.3305\n",
      "Epoch 5/20\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 535ms/step - accuracy: 0.9745 - loss: 0.1847\n",
      "Epoch 6/20\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 534ms/step - accuracy: 0.9894 - loss: 0.0944\n",
      "Epoch 7/20\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 536ms/step - accuracy: 0.9954 - loss: 0.0485\n",
      "Epoch 8/20\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 530ms/step - accuracy: 0.9976 - loss: 0.0275\n",
      "Epoch 9/20\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 545ms/step - accuracy: 0.9985 - loss: 0.0174\n",
      "Epoch 10/20\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 528ms/step - accuracy: 0.9992 - loss: 0.0108\n",
      "Epoch 11/20\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 504ms/step - accuracy: 0.9995 - loss: 0.0076\n",
      "Epoch 12/20\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 504ms/step - accuracy: 0.9997 - loss: 0.0052\n",
      "Epoch 13/20\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 526ms/step - accuracy: 0.9998 - loss: 0.0037\n",
      "Epoch 14/20\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 533ms/step - accuracy: 0.9999 - loss: 0.0029\n",
      "Epoch 15/20\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 522ms/step - accuracy: 0.9999 - loss: 0.0021\n",
      "Epoch 16/20\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 526ms/step - accuracy: 1.0000 - loss: 0.0016\n",
      "Epoch 17/20\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 511ms/step - accuracy: 1.0000 - loss: 0.0012\n",
      "Epoch 18/20\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 528ms/step - accuracy: 1.0000 - loss: 0.0010\n",
      "Epoch 19/20\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 536ms/step - accuracy: 1.0000 - loss: 8.0931e-04\n",
      "Epoch 20/20\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 513ms/step - accuracy: 1.0000 - loss: 6.4795e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2330e630140>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([Q_input, A_input], A_target, batch_size=64, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 디코더 (추론 모델) 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    encoder_outputs, h, c = encoder(input_seq)\n",
    "    target_seq = tf.zeros((1, 1), dtype=tf.int32)\n",
    "\n",
    "    decoded_sentence = ''\n",
    "\n",
    "    for _ in range(max_len):\n",
    "        output_tokens = decoder([target_seq, encoder_outputs, h, c])\n",
    "\n",
    "        # 배열이 아닌 정수로 변환\n",
    "        sampled_token_index = int(tf.argmax(output_tokens, axis=-1).numpy()[0, 0])\n",
    "\n",
    "        sampled_token = sp.IdToPiece(sampled_token_index)\n",
    "        decoded_sentence += sampled_token + ' '\n",
    "\n",
    "        if sampled_token == '</s>':\n",
    "            break\n",
    "\n",
    "        target_seq = tf.constant([[sampled_token_index]])\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 추론 함수\n",
    "- 추론 함수 생성 및 테스트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 간단한 챗봇 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    user_input = input('User: ')\n",
    "    if user_input == 'exit':\n",
    "        break\n",
    "\n",
    "    input_seq = pad_sequences([sp.EncodeAsIds(user_input)], maxlen=max_len, padding='post')\n",
    "    response = decode_sequence(input_seq)\n",
    "    print('Chatbot:', response.strip())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pystudy_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
